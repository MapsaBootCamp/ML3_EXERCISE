{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPSTTQn4hn7A"
   },
   "source": [
    "1-لابه ای برای مدل بنویسید که متن زیر را گرفته علامت های نگارشی را حذف کرده و سایز کلمات را تا 5 در نظر بگیردو خروجی  به صورت عددی باشد\n",
    "\n",
    "text = \"are/ you ready .?! yes iam resdy&()\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def process_text(text):\n",
    "    # Remove all punctuation marks\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Create a list of tuples containing the index and length of all valid words\n",
    "    lengths = [(i, len(word)) for i, word in enumerate(words) if len(word) < 5]\n",
    "    \n",
    "    return lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3), (1, 3), (3, 3), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "text = \"are/ you ready .?! yes iam resdy&()\"\n",
    "lengths = process_text(text)\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uogtIMERlzcQ"
   },
   "source": [
    "2-با استفاده از \n",
    "\n",
    "tokenizer \n",
    "\n",
    "جمله زیر را توکن بندی کنید و ایندکس های تخصیص داده شده را نشان دهید\n",
    "\n",
    "test_data = [\n",
    "  \"Enjoy coffee this morning.\",\n",
    "  \"I enjoy going to the supermarket.\",\n",
    "  \"Want some milk for your coffee?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/cmos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  # نصب داده‌های مورد نیاز برای اجرای تابع word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(sentences):\n",
    "    tokenized_dict = {}\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        token_indices = [j for j in range(len(tokens))]\n",
    "        tokenized_dict[sentence] = token_indices\n",
    "    return tokenized_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Enjoy coffee this morning.': [0, 1, 2, 3, 4], 'I enjoy going to the supermarket.': [0, 1, 2, 3, 4, 5, 6], 'Want some milk for your coffee?': [0, 1, 2, 3, 4, 5, 6]}\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    "    \"Enjoy coffee this morning.\",\n",
    "    \"I enjoy going to the supermarket.\",\n",
    "    \"Want some milk for your coffee?\"\n",
    "]\n",
    "\n",
    "result = tokenize_sentences(test_data)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJlnrCOEnJT5"
   },
   "source": [
    "3-دو روش برخورد با داده های متنی به طور کلی چیست و چه زمانی از کدام روش استقاده میکنیم؟\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words and sequential models are two different approaches for processing text data in machine learning.\n",
    "\n",
    "As I mentioned earlier, the bag of words model represents text data as a vector of word counts, where the order of the words in the text is not taken into account. This approach is simple and efficient, but it does not capture the context or meaning of the words.\n",
    "\n",
    "On the other hand, sequential models, such as recurrent neural networks (RNNs), take into account the order of the words in the text by processing them sequentially. RNNs are designed to maintain an internal state that captures information about the previous words in the sequence, which allows them to make predictions about the next word.\n",
    "\n",
    "Sequential models are more complex and computationally intensive than bag of words models, but they can capture more information about the text, such as the context and meaning of the words. They are particularly useful for tasks such as natural language processing, where the meaning of the text is important.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- فرمانی بنویسید که متنی را خوانده و هر جا اسم شما بود را با کلمه دیگری \n",
    "جایگزین کرده و آن را در فایل جدیدی ذخیره کند\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sed 's/maryam/mery/g' text.txt > new_text.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- پرینت کنید services ردیف سوم فایل"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "awk 'NR==3' /etc/services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aol8RBXOoSJM"
   },
   "source": [
    "3- vimدستورات زیر در \n",
    "\n",
    "چکاری انجام می دهند\n",
    "\n",
    "/\n",
    "\n",
    "escape\n",
    "\n",
    ":\n",
    "\n",
    ":wq\n",
    "\n",
    "x\n",
    "\n",
    ":q!\n",
    "\n",
    "u\n",
    "\n",
    "ctl + r\n",
    "\n",
    "d+4+d\n",
    "\n",
    "p\n",
    "\n",
    "y+2+y\n",
    "\n",
    "dd\n",
    "\n",
    "yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWIWi_MXxniS"
   },
   "source": [
    "/: This command allows the user to search for a pattern in the file that is open in vim. For example, if you want to search for the string \"hello\" in the file, you can enter the command /hello.\n",
    "\n",
    "escape: This command allows the user to exit insert mode and return to command mode in vim.\n",
    "\n",
    ":wq: This command saves the file and exits vim editor.\n",
    "\n",
    "x: This command deletes the character under the cursor in vim.\n",
    "\n",
    ":q!: This command closes vim without saving the file.\n",
    "\n",
    "u: This command undoes the last action performed in the file.\n",
    "\n",
    "ctl + r: This command undoes the undo action and performs the redo action in vim.\n",
    "\n",
    "d+4+d: This command deletes four lines of text in vim.\n",
    "\n",
    "p: This command pastes the text that was copied into the buffer at the location of the cursor in vim.\n",
    "\n",
    "y+2+y: This command copies two lines of text in vim.\n",
    "\n",
    "dd: This command deletes one line of text in vim.\n",
    "\n",
    "yy: This command copies one line of text in vim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- کامندی برای کنترل رمان استفاده از لینوکس"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date +%Y%m%d -s \"20220415\"\n",
    "date +%T -s \"12:34:56\"\n",
    "watch -n 1 date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date +%Y%m%d -s \"20220415\": This command sets the system date to April 15th, 2022 (20220415) in the format of year, month, and day (YYYYMMDD).\n",
    "\n",
    "date +%T -s \"12:34:56\": This command sets the system time to 12:34:56 in the format of hour, minute, and second (HH:MM:SS).\n",
    "\n",
    "watch -n 1 date: This command continuously displays the current date and time on the terminal with a refresh rate of 1 second. The watch command is used to execute a command repeatedly, and in this case, the command being executed is date."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
