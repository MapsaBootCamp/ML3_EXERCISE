{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c31b86-dc76-4f81-bfa1-8d212ff81f54",
   "metadata": {},
   "source": [
    "<div dir = \"rtl\" style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=6 color=#F32500>\n",
    "        <div  align=center>\n",
    "            تمرین هفته دهم بوت کمپ یادگیری ماشین-\n",
    "            مپصا\n",
    "        </div>\n",
    "        <br/>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f383f6fe-a565-4990-82c6-dfbab8a0002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and libraries here.\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e3c3a8-c6b3-4277-96db-ec4b30a051b3",
   "metadata": {},
   "source": [
    "# 1- State with reasons whether the following sentences are true or false?\n",
    "\n",
    "<ul style=\"font-size:25px\">\n",
    "    <li>\n",
    "        SVMs are not suitable for large datasets.\n",
    "    </li>\n",
    "    <li>\n",
    "       SVMs perform poorly in imbalanced datasets.\n",
    "    </li>\n",
    "     <li>\n",
    "        SVMs perform poorly when there is just too much noise in the data.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc1516b",
   "metadata": {},
   "source": [
    "##  SVMs are not suitable for large datasets----->True                                  \n",
    "normal SVM is not suitable for classification of large data sets, because the training complexity of SVM is very high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5bdc7c",
   "metadata": {},
   "source": [
    "## SVMs perform poorly in imbalanced datasets.------->True                                     \n",
    "SVMs are effective models for binary classification tasks, although by default, they are not effective at imbalanced classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc6f4b9",
   "metadata": {},
   "source": [
    "## SVMs perform poorly when there is just too much noise in the data----->True                  \n",
    "SVM will not perform well with data with more noise because of the weakness of soft margin optimization issue. The unique hyperplane grabbed in the SVM process using the imbalanced data will be fully skewed towards a minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37b1b2d-a239-4a41-bcc4-178e09e8bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4eb95-8d60-4d68-a859-5d7007178d0f",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t ۲- دیتاست lsvt-voice-rehabilitation را از لینک زیر دانلود کنید و به سوالات زیر حواب دهید. در این تمرین مجاز به استفاده از کتابخانه scikit-learn می باشید.\n",
    "\t\t</br>\n",
    "</div>\n",
    "\t\thttps://archive.ics.uci.edu/ml/datasets/LSVT+Voice+Rehabilitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bab33f80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jitter-&gt;F0_abs_dif</th>\n",
       "      <th>Jitter-&gt;F0_dif_percent</th>\n",
       "      <th>Jitter-&gt;F0_PQ5_classical_Schoentgen</th>\n",
       "      <th>Jitter-&gt;F0_PQ5_classical_Baken</th>\n",
       "      <th>Jitter-&gt;F0_PQ5_generalised_Schoentgen</th>\n",
       "      <th>Jitter-&gt;F0_abs0th_perturb</th>\n",
       "      <th>Jitter-&gt;F0_CV</th>\n",
       "      <th>Jitter-&gt;F0_TKEO_mean</th>\n",
       "      <th>Jitter-&gt;F0_TKEO_std</th>\n",
       "      <th>Jitter-&gt;F0_TKEO_prc5</th>\n",
       "      <th>...</th>\n",
       "      <th>det_TKEO_std4_1_coef</th>\n",
       "      <th>det_TKEO_std4_2_coef</th>\n",
       "      <th>det_TKEO_std4_3_coef</th>\n",
       "      <th>det_TKEO_std4_4_coef</th>\n",
       "      <th>det_TKEO_std4_5_coef</th>\n",
       "      <th>det_TKEO_std4_6_coef</th>\n",
       "      <th>det_TKEO_std4_7_coef</th>\n",
       "      <th>det_TKEO_std4_8_coef</th>\n",
       "      <th>det_TKEO_std4_9_coef</th>\n",
       "      <th>det_TKEO_std4_10_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088112</td>\n",
       "      <td>0.041697</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>-3.723304e-06</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>2.458381</td>\n",
       "      <td>6.332164e-07</td>\n",
       "      <td>47.021079</td>\n",
       "      <td>1366.430390</td>\n",
       "      <td>-7.103323</td>\n",
       "      <td>...</td>\n",
       "      <td>2.527583</td>\n",
       "      <td>7.088978</td>\n",
       "      <td>19.753255</td>\n",
       "      <td>54.335046</td>\n",
       "      <td>145.528630</td>\n",
       "      <td>375.097397</td>\n",
       "      <td>921.296579</td>\n",
       "      <td>2137.079844</td>\n",
       "      <td>4697.131077</td>\n",
       "      <td>9931.208257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.161798</td>\n",
       "      <td>0.057364</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>5.466365e-06</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>2.592066</td>\n",
       "      <td>7.228518e-07</td>\n",
       "      <td>93.557936</td>\n",
       "      <td>2582.922776</td>\n",
       "      <td>-23.284761</td>\n",
       "      <td>...</td>\n",
       "      <td>2.841881</td>\n",
       "      <td>7.977363</td>\n",
       "      <td>22.203504</td>\n",
       "      <td>60.993338</td>\n",
       "      <td>163.560972</td>\n",
       "      <td>421.010306</td>\n",
       "      <td>1036.092589</td>\n",
       "      <td>2404.072562</td>\n",
       "      <td>5284.082128</td>\n",
       "      <td>11165.095662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.554508</td>\n",
       "      <td>0.642913</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>-7.443871e-07</td>\n",
       "      <td>0.006488</td>\n",
       "      <td>12.691326</td>\n",
       "      <td>6.946246e-04</td>\n",
       "      <td>52.988422</td>\n",
       "      <td>466.682635</td>\n",
       "      <td>-45.308680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.806103</td>\n",
       "      <td>5.078616</td>\n",
       "      <td>14.135923</td>\n",
       "      <td>38.641654</td>\n",
       "      <td>103.466808</td>\n",
       "      <td>264.654626</td>\n",
       "      <td>649.657090</td>\n",
       "      <td>1507.384591</td>\n",
       "      <td>3315.804236</td>\n",
       "      <td>6974.600636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031089</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>-2.214722e-07</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.754288</td>\n",
       "      <td>1.868647e-07</td>\n",
       "      <td>13.982754</td>\n",
       "      <td>417.217249</td>\n",
       "      <td>-1.207741</td>\n",
       "      <td>...</td>\n",
       "      <td>1.999637</td>\n",
       "      <td>5.610448</td>\n",
       "      <td>15.626164</td>\n",
       "      <td>42.943275</td>\n",
       "      <td>115.014975</td>\n",
       "      <td>296.320795</td>\n",
       "      <td>728.284936</td>\n",
       "      <td>1689.586636</td>\n",
       "      <td>3713.818933</td>\n",
       "      <td>7851.139360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076177</td>\n",
       "      <td>0.039071</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>2.732106e-05</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>1.270034</td>\n",
       "      <td>4.918186e-05</td>\n",
       "      <td>56.373996</td>\n",
       "      <td>1608.317410</td>\n",
       "      <td>-3.491990</td>\n",
       "      <td>...</td>\n",
       "      <td>2.453087</td>\n",
       "      <td>6.902199</td>\n",
       "      <td>19.117609</td>\n",
       "      <td>52.715873</td>\n",
       "      <td>141.113865</td>\n",
       "      <td>363.511021</td>\n",
       "      <td>893.246151</td>\n",
       "      <td>2071.625622</td>\n",
       "      <td>4554.204815</td>\n",
       "      <td>9623.566242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Jitter->F0_abs_dif  Jitter->F0_dif_percent  \\\n",
       "0            0.088112                0.041697   \n",
       "1            0.161798                0.057364   \n",
       "2            0.554508                0.642913   \n",
       "3            0.031089                0.027108   \n",
       "4            0.076177                0.039071   \n",
       "\n",
       "   Jitter->F0_PQ5_classical_Schoentgen  Jitter->F0_PQ5_classical_Baken  \\\n",
       "0                             0.000480                   -3.723304e-06   \n",
       "1                             0.000677                    5.466365e-06   \n",
       "2                             0.007576                   -7.443871e-07   \n",
       "3                             0.000314                   -2.214722e-07   \n",
       "4                             0.000302                    2.732106e-05   \n",
       "\n",
       "   Jitter->F0_PQ5_generalised_Schoentgen  Jitter->F0_abs0th_perturb  \\\n",
       "0                               0.000422                   2.458381   \n",
       "1                               0.000206                   2.592066   \n",
       "2                               0.006488                  12.691326   \n",
       "3                               0.000216                   0.754288   \n",
       "4                               0.001102                   1.270034   \n",
       "\n",
       "   Jitter->F0_CV  Jitter->F0_TKEO_mean  Jitter->F0_TKEO_std  \\\n",
       "0   6.332164e-07             47.021079          1366.430390   \n",
       "1   7.228518e-07             93.557936          2582.922776   \n",
       "2   6.946246e-04             52.988422           466.682635   \n",
       "3   1.868647e-07             13.982754           417.217249   \n",
       "4   4.918186e-05             56.373996          1608.317410   \n",
       "\n",
       "   Jitter->F0_TKEO_prc5  ...  det_TKEO_std4_1_coef  det_TKEO_std4_2_coef  \\\n",
       "0             -7.103323  ...              2.527583              7.088978   \n",
       "1            -23.284761  ...              2.841881              7.977363   \n",
       "2            -45.308680  ...              1.806103              5.078616   \n",
       "3             -1.207741  ...              1.999637              5.610448   \n",
       "4             -3.491990  ...              2.453087              6.902199   \n",
       "\n",
       "   det_TKEO_std4_3_coef  det_TKEO_std4_4_coef  det_TKEO_std4_5_coef  \\\n",
       "0             19.753255             54.335046            145.528630   \n",
       "1             22.203504             60.993338            163.560972   \n",
       "2             14.135923             38.641654            103.466808   \n",
       "3             15.626164             42.943275            115.014975   \n",
       "4             19.117609             52.715873            141.113865   \n",
       "\n",
       "   det_TKEO_std4_6_coef  det_TKEO_std4_7_coef  det_TKEO_std4_8_coef  \\\n",
       "0            375.097397            921.296579           2137.079844   \n",
       "1            421.010306           1036.092589           2404.072562   \n",
       "2            264.654626            649.657090           1507.384591   \n",
       "3            296.320795            728.284936           1689.586636   \n",
       "4            363.511021            893.246151           2071.625622   \n",
       "\n",
       "   det_TKEO_std4_9_coef  det_TKEO_std4_10_coef  \n",
       "0           4697.131077            9931.208257  \n",
       "1           5284.082128           11165.095662  \n",
       "2           3315.804236            6974.600636  \n",
       "3           3713.818933            7851.139360  \n",
       "4           4554.204815            9623.566242  \n",
       "\n",
       "[5 rows x 310 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('LSVT_voice_rehabilitation.xlsx')\n",
    "target=pd.read_excel('LSVT_voice_rehabilitation.xlsx',sheet_name ='Binary response')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "94c6a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.columns=['lable']\n",
    "df=pd.concat([df,target],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "af006311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jitter-&gt;F0_abs_dif</th>\n",
       "      <th>Jitter-&gt;F0_dif_percent</th>\n",
       "      <th>Jitter-&gt;F0_PQ5_classical_Schoentgen</th>\n",
       "      <th>Jitter-&gt;F0_PQ5_classical_Baken</th>\n",
       "      <th>Jitter-&gt;F0_PQ5_generalised_Schoentgen</th>\n",
       "      <th>Jitter-&gt;F0_abs0th_perturb</th>\n",
       "      <th>Jitter-&gt;F0_CV</th>\n",
       "      <th>Jitter-&gt;F0_TKEO_mean</th>\n",
       "      <th>Jitter-&gt;F0_TKEO_std</th>\n",
       "      <th>Jitter-&gt;F0_TKEO_prc5</th>\n",
       "      <th>...</th>\n",
       "      <th>det_TKEO_std4_2_coef</th>\n",
       "      <th>det_TKEO_std4_3_coef</th>\n",
       "      <th>det_TKEO_std4_4_coef</th>\n",
       "      <th>det_TKEO_std4_5_coef</th>\n",
       "      <th>det_TKEO_std4_6_coef</th>\n",
       "      <th>det_TKEO_std4_7_coef</th>\n",
       "      <th>det_TKEO_std4_8_coef</th>\n",
       "      <th>det_TKEO_std4_9_coef</th>\n",
       "      <th>det_TKEO_std4_10_coef</th>\n",
       "      <th>lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088112</td>\n",
       "      <td>0.041697</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>-3.723304e-06</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>2.458381</td>\n",
       "      <td>6.332164e-07</td>\n",
       "      <td>47.021079</td>\n",
       "      <td>1366.430390</td>\n",
       "      <td>-7.103323</td>\n",
       "      <td>...</td>\n",
       "      <td>7.088978</td>\n",
       "      <td>19.753255</td>\n",
       "      <td>54.335046</td>\n",
       "      <td>145.528630</td>\n",
       "      <td>375.097397</td>\n",
       "      <td>921.296579</td>\n",
       "      <td>2137.079844</td>\n",
       "      <td>4697.131077</td>\n",
       "      <td>9931.208257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.161798</td>\n",
       "      <td>0.057364</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>5.466365e-06</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>2.592066</td>\n",
       "      <td>7.228518e-07</td>\n",
       "      <td>93.557936</td>\n",
       "      <td>2582.922776</td>\n",
       "      <td>-23.284761</td>\n",
       "      <td>...</td>\n",
       "      <td>7.977363</td>\n",
       "      <td>22.203504</td>\n",
       "      <td>60.993338</td>\n",
       "      <td>163.560972</td>\n",
       "      <td>421.010306</td>\n",
       "      <td>1036.092589</td>\n",
       "      <td>2404.072562</td>\n",
       "      <td>5284.082128</td>\n",
       "      <td>11165.095662</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.554508</td>\n",
       "      <td>0.642913</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>-7.443871e-07</td>\n",
       "      <td>0.006488</td>\n",
       "      <td>12.691326</td>\n",
       "      <td>6.946246e-04</td>\n",
       "      <td>52.988422</td>\n",
       "      <td>466.682635</td>\n",
       "      <td>-45.308680</td>\n",
       "      <td>...</td>\n",
       "      <td>5.078616</td>\n",
       "      <td>14.135923</td>\n",
       "      <td>38.641654</td>\n",
       "      <td>103.466808</td>\n",
       "      <td>264.654626</td>\n",
       "      <td>649.657090</td>\n",
       "      <td>1507.384591</td>\n",
       "      <td>3315.804236</td>\n",
       "      <td>6974.600636</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031089</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>-2.214722e-07</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.754288</td>\n",
       "      <td>1.868647e-07</td>\n",
       "      <td>13.982754</td>\n",
       "      <td>417.217249</td>\n",
       "      <td>-1.207741</td>\n",
       "      <td>...</td>\n",
       "      <td>5.610448</td>\n",
       "      <td>15.626164</td>\n",
       "      <td>42.943275</td>\n",
       "      <td>115.014975</td>\n",
       "      <td>296.320795</td>\n",
       "      <td>728.284936</td>\n",
       "      <td>1689.586636</td>\n",
       "      <td>3713.818933</td>\n",
       "      <td>7851.139360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076177</td>\n",
       "      <td>0.039071</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>2.732106e-05</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>1.270034</td>\n",
       "      <td>4.918186e-05</td>\n",
       "      <td>56.373996</td>\n",
       "      <td>1608.317410</td>\n",
       "      <td>-3.491990</td>\n",
       "      <td>...</td>\n",
       "      <td>6.902199</td>\n",
       "      <td>19.117609</td>\n",
       "      <td>52.715873</td>\n",
       "      <td>141.113865</td>\n",
       "      <td>363.511021</td>\n",
       "      <td>893.246151</td>\n",
       "      <td>2071.625622</td>\n",
       "      <td>4554.204815</td>\n",
       "      <td>9623.566242</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 311 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Jitter->F0_abs_dif  Jitter->F0_dif_percent  \\\n",
       "0            0.088112                0.041697   \n",
       "1            0.161798                0.057364   \n",
       "2            0.554508                0.642913   \n",
       "3            0.031089                0.027108   \n",
       "4            0.076177                0.039071   \n",
       "\n",
       "   Jitter->F0_PQ5_classical_Schoentgen  Jitter->F0_PQ5_classical_Baken  \\\n",
       "0                             0.000480                   -3.723304e-06   \n",
       "1                             0.000677                    5.466365e-06   \n",
       "2                             0.007576                   -7.443871e-07   \n",
       "3                             0.000314                   -2.214722e-07   \n",
       "4                             0.000302                    2.732106e-05   \n",
       "\n",
       "   Jitter->F0_PQ5_generalised_Schoentgen  Jitter->F0_abs0th_perturb  \\\n",
       "0                               0.000422                   2.458381   \n",
       "1                               0.000206                   2.592066   \n",
       "2                               0.006488                  12.691326   \n",
       "3                               0.000216                   0.754288   \n",
       "4                               0.001102                   1.270034   \n",
       "\n",
       "   Jitter->F0_CV  Jitter->F0_TKEO_mean  Jitter->F0_TKEO_std  \\\n",
       "0   6.332164e-07             47.021079          1366.430390   \n",
       "1   7.228518e-07             93.557936          2582.922776   \n",
       "2   6.946246e-04             52.988422           466.682635   \n",
       "3   1.868647e-07             13.982754           417.217249   \n",
       "4   4.918186e-05             56.373996          1608.317410   \n",
       "\n",
       "   Jitter->F0_TKEO_prc5  ...  det_TKEO_std4_2_coef  det_TKEO_std4_3_coef  \\\n",
       "0             -7.103323  ...              7.088978             19.753255   \n",
       "1            -23.284761  ...              7.977363             22.203504   \n",
       "2            -45.308680  ...              5.078616             14.135923   \n",
       "3             -1.207741  ...              5.610448             15.626164   \n",
       "4             -3.491990  ...              6.902199             19.117609   \n",
       "\n",
       "   det_TKEO_std4_4_coef  det_TKEO_std4_5_coef  det_TKEO_std4_6_coef  \\\n",
       "0             54.335046            145.528630            375.097397   \n",
       "1             60.993338            163.560972            421.010306   \n",
       "2             38.641654            103.466808            264.654626   \n",
       "3             42.943275            115.014975            296.320795   \n",
       "4             52.715873            141.113865            363.511021   \n",
       "\n",
       "   det_TKEO_std4_7_coef  det_TKEO_std4_8_coef  det_TKEO_std4_9_coef  \\\n",
       "0            921.296579           2137.079844           4697.131077   \n",
       "1           1036.092589           2404.072562           5284.082128   \n",
       "2            649.657090           1507.384591           3315.804236   \n",
       "3            728.284936           1689.586636           3713.818933   \n",
       "4            893.246151           2071.625622           4554.204815   \n",
       "\n",
       "   det_TKEO_std4_10_coef  lable  \n",
       "0            9931.208257      1  \n",
       "1           11165.095662      2  \n",
       "2            6974.600636      2  \n",
       "3            7851.139360      1  \n",
       "4            9623.566242      2  \n",
       "\n",
       "[5 rows x 311 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cdb4b5-e80e-41db-b3a5-e495247bb679",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t الف- داده ها را به روشهای زیر دسته بندی کنید (حواستان باشد که داده ها را قبل از اعمال به مدل، نرمالایز کنید).\n",
    "        <ul>\n",
    "            <li>\n",
    "            کرنل خطی\n",
    "            </li>\n",
    "            <li>\n",
    "            کرنل چندجمله ای (پارامترهای r, d)\n",
    "            </li>\n",
    "            <li>\n",
    "            کرنل rbf - پارامتر گاما\n",
    "            </li>\n",
    "            <li>\n",
    "            سیگمویید - پارامتر r\n",
    "            </li>           \n",
    "         </ul>\n",
    "</div"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a7d0b1-9500-4a57-9fd1-5230eb3f9184",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t ب- معیار دقت و f1 را برای هریک از دسته بندی های قسمت الف به دست آورید. (برای هر یک از پارامترهای گفته شده حداقل سه مقدار مختلف در نظر بگیرید)\n",
    "\t\t</br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d92c8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bb2d71df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('lable', axis=1)\n",
    "y = df['lable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "48a48a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4e7e50d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  1]\n",
      " [ 1 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.88      0.88         8\n",
      "           2       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.91      0.91      0.91        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n",
      "0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "linear = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='linear'))\n",
    "linear.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = linear.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred1))\n",
    "print(classification_report(y_test,y_pred1))\n",
    "print(accuracy_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5d747284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  7]\n",
      " [ 0 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.12      0.22         8\n",
      "           2       0.72      1.00      0.84        18\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.86      0.56      0.53        26\n",
      "weighted avg       0.81      0.73      0.65        26\n",
      "\n",
      "0.7307692307692307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "poly = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='poly', degree=2))\n",
    "poly.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = poly.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred2))\n",
    "print(classification_report(y_test, y_pred2))\n",
    "print(accuracy_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8122f8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "42353b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  3]\n",
      " [ 0 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.62      0.77         8\n",
      "           2       0.86      1.00      0.92        18\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.93      0.81      0.85        26\n",
      "weighted avg       0.90      0.88      0.88        26\n",
      "\n",
      "0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "rbf = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='rbf'))\n",
    "rbf.fit(X_train, y_train)\n",
    "\n",
    "y_pred3 = rbf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred3))\n",
    "print(classification_report(y_test, y_pred3))\n",
    "print(accuracy_score(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7638bca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9b39ac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  1]\n",
      " [ 1 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.88      0.88         8\n",
      "           2       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.91      0.91      0.91        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n",
      "0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "sigmoid = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='sigmoid'))\n",
    "sigmoid.fit(X_train, y_train)\n",
    "\n",
    "y_pred4 = sigmoid.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred1))\n",
    "print(classification_report(y_test, y_pred1))\n",
    "print(accuracy_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a6660b-18d8-40ac-b651-f1df747b871f",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t ج- تاثیر پارامترهای هر کرنل را بر کارآیی مدل ها تحلیل کنید.\n",
    "\t\t</br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5ebea37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  1]\n",
      " [ 1 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.88      0.88         8\n",
      "           2       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.91      0.91      0.91        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n",
      "0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "linear = make_pipeline(preprocessing.StandardScaler(),SVC(C=10,kernel='linear',gamma=11))\n",
    "linear.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = linear.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred1))\n",
    "print(classification_report(y_test,y_pred1))\n",
    "print(accuracy_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4a6d5a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  3]\n",
      " [ 1 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.62      0.71         8\n",
      "           2       0.85      0.94      0.89        18\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.84      0.78      0.80        26\n",
      "weighted avg       0.84      0.85      0.84        26\n",
      "\n",
      "0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "poly = make_pipeline(preprocessing.StandardScaler(),SVC(C=10,kernel='poly', degree=2,gamma=3))\n",
    "poly.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = poly.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred2))\n",
    "print(classification_report(y_test, y_pred2))\n",
    "print(accuracy_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3558b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  8]\n",
      " [ 0 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.69      1.00      0.82        18\n",
      "\n",
      "    accuracy                           0.69        26\n",
      "   macro avg       0.35      0.50      0.41        26\n",
      "weighted avg       0.48      0.69      0.57        26\n",
      "\n",
      "0.6923076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sara/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sara/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sara/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "rbf = make_pipeline(preprocessing.StandardScaler(),SVC(C=1,kernel='rbf',gamma=1))\n",
    "rbf.fit(X_train, y_train)\n",
    "\n",
    "y_pred3 = rbf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred3))\n",
    "print(classification_report(y_test, y_pred3))\n",
    "print(accuracy_score(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2540f687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  1]\n",
      " [ 1 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.88      0.88         8\n",
      "           2       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.91      0.91      0.91        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n",
      "0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "sigmoid = make_pipeline(preprocessing.StandardScaler(),SVC(C=1,kernel='sigmoid',gamma=2))\n",
    "sigmoid.fit(X_train, y_train)\n",
    "\n",
    "y_pred4 = sigmoid.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred1))\n",
    "print(classification_report(y_test, y_pred1))\n",
    "print(accuracy_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7201b1-1800-4e9d-ae00-7cb5c9d673c8",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t د- کدام مدل عملکرد بهتری دارد؟ چرا؟\n",
    "\t\t</br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68ac6ff",
   "metadata": {},
   "source": [
    "با در نظر گرفتن مقدار دیفالت پارامتر ها کرنل سیگموید و لینیر بیشترین دقت را داشته اند\n",
    "با افزایش مقدار سی و گاما دفت کرنل پلی افزایش یافت و مدل ار بی اف, دقت آن کاهش یافت"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028f455-56e3-489b-94c3-1f77e9460a4d",
   "metadata": {},
   "source": [
    "# 3- Student Intervention System\n",
    "\n",
    "<div style=\"margin-left: 10px;font-size:25px\">a) Run the code cell below to load necessary Python libraries and load the student data. Note that the last column from this dataset, 'passed', will be our target label (whether the student graduated or didn't graduate). All other columns are features about each student.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6b3d38d1-e78a-4017-adca-b296225645b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 31 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   school      395 non-null    object\n",
      " 1   sex         395 non-null    object\n",
      " 2   age         395 non-null    int64 \n",
      " 3   address     395 non-null    object\n",
      " 4   famsize     395 non-null    object\n",
      " 5   Pstatus     395 non-null    object\n",
      " 6   Medu        395 non-null    int64 \n",
      " 7   Fedu        395 non-null    int64 \n",
      " 8   Mjob        395 non-null    object\n",
      " 9   Fjob        395 non-null    object\n",
      " 10  reason      395 non-null    object\n",
      " 11  guardian    395 non-null    object\n",
      " 12  traveltime  395 non-null    int64 \n",
      " 13  studytime   395 non-null    int64 \n",
      " 14  failures    395 non-null    int64 \n",
      " 15  schoolsup   395 non-null    object\n",
      " 16  famsup      395 non-null    object\n",
      " 17  paid        395 non-null    object\n",
      " 18  activities  395 non-null    object\n",
      " 19  nursery     395 non-null    object\n",
      " 20  higher      395 non-null    object\n",
      " 21  internet    395 non-null    object\n",
      " 22  romantic    395 non-null    object\n",
      " 23  famrel      395 non-null    int64 \n",
      " 24  freetime    395 non-null    int64 \n",
      " 25  goout       395 non-null    int64 \n",
      " 26  Dalc        395 non-null    int64 \n",
      " 27  Walc        395 non-null    int64 \n",
      " 28  health      395 non-null    int64 \n",
      " 29  absences    395 non-null    int64 \n",
      " 30  passed      395 non-null    object\n",
      "dtypes: int64(13), object(18)\n",
      "memory usage: 95.8+ KB\n"
     ]
    }
   ],
   "source": [
    "student_data = pd.read_csv(\"student_data.csv\")\n",
    "student_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd5509-8974-44c8-87c9-06e5aefb475c",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 10px;font-size:25px\">\n",
    "  <p>  \n",
    "b) Let's begin by investigating the dataset to determine how many students we have information on, and learn about the graduation rate among these students. In the code cell below, you will need to compute the following:\n",
    "    </p>\n",
    "    <ul>\n",
    "        <li>The total number of students, n_students.</li>\n",
    "        <li>The total number of features for each student, n_features.</li>\n",
    "        <li>The number of those students who passed, n_passed.</li>\n",
    "        <li>The number of those students who failed, n_failed.</li>\n",
    "        <li>The graduation rate of the class, grad_rate, in percent (%).</li>\n",
    "     </ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "75834b0c-fd2a-45ae-bb4b-041b53ea039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of features: 31\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Graduation rate of the class: 0.67%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate number of students\n",
    "\n",
    "n_students = student_data.shape[0]\n",
    "\n",
    "# TODO: Calculate number of features\n",
    "\n",
    "n_features = student_data.shape[1]\n",
    "\n",
    "# TODO: Calculate passing students\n",
    "\n",
    "n_passed = student_data[student_data['passed']=='yes']['passed'].count()\n",
    "\n",
    "# TODO: Calculate failing students\n",
    "n_failed = student_data[student_data['passed']=='no']['passed'].count()\n",
    "\n",
    "# TODO: Calculate graduation rate\n",
    "total=student_data['passed'].count()\n",
    "grad_rate = n_passed/total\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of students: {}\".format(n_students))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of students who passed: {}\".format(n_passed))\n",
    "print(\"Number of students who failed: {}\".format(n_failed))\n",
    "print(\"Graduation rate of the class: {:.2f}%\".format(grad_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb98764-1eab-402f-a9c6-846417c02d75",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"margin-left: 10px;font-size:25px\">\n",
    "    <p>c) Preparing the Data</p>\n",
    "    <p>In this section, we will prepare the data for modeling, training and testing.</p>\n",
    "    <p>Identify feature and target columns\n",
    "It is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "Run the code cell below to separate the student data into feature and target columns to see if any features are non-numeric.</p>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "62d65bfa-7b48-406d-b496-cb27a4db5139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Target column: passed\n"
     ]
    }
   ],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# Extract target column 'passed'\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# Show the list of columns\n",
    "print(\"Feature columns:\\n{}\".format(feature_cols))\n",
    "print(\"\\nTarget column: {}\".format(target_col))\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X = student_data[feature_cols]\n",
    "y = student_data[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a82fa-9a11-4ad5-8ed1-e61086fa3874",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 10px;font-size:25px\">\n",
    "    <p>d) Preprocess Feature Columns</p>\n",
    "    <p>As you can see, there are several non-numeric columns that need to be converted! Many of them are simply yes/no, e.g. internet. These can be reasonably converted into 1/0 (binary) values.</p>\n",
    "    <p>\n",
    "Other columns, like Mjob and Fjob, have more than two values, and are known as categorical variables. The recommended way to handle such a column is to create as many columns as possible values (e.g. Fjob_teacher, Fjob_other, Fjob_services, etc.), and assign a 1 to one of them and 0 to all others.\n",
    "\n",
    "These generated columns are sometimes called dummy variables, and we will use the pandas.get_dummies() function to perform this transformation. Run the code cell below to perform the preprocessing routine discussed in this section.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "37fa60c9-b048-443a-8833-3717c637f93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****binary*****\n",
      "col name:  school----unique values:  ['GP' 'MS']\n",
      "*****binary*****\n",
      "col name:  sex----unique values:  ['F' 'M']\n",
      "*****binary*****\n",
      "col name:  address----unique values:  ['U' 'R']\n",
      "*****binary*****\n",
      "col name:  famsize----unique values:  ['GT3' 'LE3']\n",
      "*****binary*****\n",
      "col name:  Pstatus----unique values:  ['A' 'T']\n",
      "*****categorical*****\n",
      "col name:  Mjob----unique values:  ['at_home' 'health' 'other' 'services' 'teacher']\n",
      "*****categorical*****\n",
      "col name:  Fjob----unique values:  ['teacher' 'other' 'services' 'health' 'at_home']\n",
      "*****categorical*****\n",
      "col name:  reason----unique values:  ['course' 'other' 'home' 'reputation']\n",
      "*****categorical*****\n",
      "col name:  guardian----unique values:  ['mother' 'father' 'other']\n",
      "*****binary*****\n",
      "col name:  schoolsup----unique values:  ['yes' 'no']\n",
      "*****binary*****\n",
      "col name:  famsup----unique values:  ['no' 'yes']\n",
      "*****binary*****\n",
      "col name:  paid----unique values:  ['no' 'yes']\n",
      "*****binary*****\n",
      "col name:  activities----unique values:  ['no' 'yes']\n",
      "*****binary*****\n",
      "col name:  nursery----unique values:  ['yes' 'no']\n",
      "*****binary*****\n",
      "col name:  higher----unique values:  ['yes' 'no']\n",
      "*****binary*****\n",
      "col name:  internet----unique values:  ['no' 'yes']\n",
      "*****binary*****\n",
      "col name:  romantic----unique values:  ['no' 'yes']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob_at_home</th>\n",
       "      <th>Mjob_health</th>\n",
       "      <th>...</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob_at_home  \\\n",
       "0         1    1   18        1        1        1     4     4             1   \n",
       "1         1    1   17        1        1        0     1     1             1   \n",
       "2         1    1   15        1        0        0     1     1             1   \n",
       "3         1    1   15        1        1        0     4     2             0   \n",
       "4         1    1   16        1        1        0     3     3             0   \n",
       "..      ...  ...  ...      ...      ...      ...   ...   ...           ...   \n",
       "390       0    0   20        1        0        1     2     2             0   \n",
       "391       0    0   17        1        0        0     3     1             0   \n",
       "392       0    0   21        0        1        0     1     1             0   \n",
       "393       0    0   18        0        0        0     3     2             0   \n",
       "394       0    0   19        1        0        0     1     1             0   \n",
       "\n",
       "     Mjob_health  ...  higher  internet  romantic  famrel  freetime  goout  \\\n",
       "0              0  ...       1         1         1       4         3      4   \n",
       "1              0  ...       1         0         1       5         3      3   \n",
       "2              0  ...       1         0         1       4         3      2   \n",
       "3              1  ...       1         0         0       3         2      2   \n",
       "4              0  ...       1         1         1       4         3      2   \n",
       "..           ...  ...     ...       ...       ...     ...       ...    ...   \n",
       "390            0  ...       1         1         1       5         5      4   \n",
       "391            0  ...       1         0         1       2         4      5   \n",
       "392            0  ...       1         1         1       5         5      3   \n",
       "393            0  ...       1         0         1       4         4      1   \n",
       "394            0  ...       1         0         1       3         2      3   \n",
       "\n",
       "     Dalc  Walc  health  absences  \n",
       "0       1     1       3         6  \n",
       "1       1     1       3         4  \n",
       "2       2     3       3        10  \n",
       "3       1     1       5         2  \n",
       "4       1     2       5         4  \n",
       "..    ...   ...     ...       ...  \n",
       "390     4     5       4        11  \n",
       "391     3     4       2         3  \n",
       "392     3     3       3         3  \n",
       "393     3     4       5         0  \n",
       "394     3     3       5         5  \n",
       "\n",
       "[395 rows x 43 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the student data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.items():\n",
    "\n",
    "        # If data type is non-numeric, replace all binary values with 1/0\n",
    "        if col_data.dtype == object and len(col_data.unique()) == 2:\n",
    "            print(\"*****binary*****\")\n",
    "            print(\"col name: \", col, end=\"----\")\n",
    "            col_data_unique = col_data.unique()\n",
    "            print(\"unique values: \", col_data_unique)\n",
    "            col_data = col_data.replace(col_data_unique, [1, 0])\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object and len(col_data.unique()) != 2:\n",
    "            print(\"*****categorical*****\")\n",
    "            print(\"col name: \", col, end=\"----\")\n",
    "            col_data_unique = col_data.unique()\n",
    "            print(\"unique values: \", col_data_unique)\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_preprocessed = preprocess_features(X)\n",
    "X_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730323a6-decd-4da0-9f56-d15cb7126fe1",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 10px;font-size:25px\">\n",
    "    <p>e) Training and Testing Data Split</p>\n",
    "    <p>split the data (both features and corresponding labels) into training and test sets.(Use 300 training points (approximately 75%) and 95 testing points (approximately 25%).)</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5d854097-e759-4d75-aa94-d02bdd5a017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import any additional functionality you may need here\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.25, random_state=55)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba84511-5161-437b-9ae1-625aaaed87e6",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 10px;font-size:25px\">\n",
    "<p>f) In this section, you will choose 3 supervised learning models that are appropriate for this problem and available in scikit-learn. You will first discuss the reasoning behind choosing these three models by considering what you know about the data and each model's strengths and weaknesses. You will then fit the model to training data and measure the F1 score. You will need to produce three tables (one for each model) that shows the training set size, training time, prediction time, F1 score on the training set, and F1 score on the testing set.</p>\n",
    "<p>The following supervised learning models are currently available in scikit-learn that you may choose from:</p>\n",
    "    <ul>\n",
    "        <li>Gaussian Naive Bayes (GaussianNB)</li>\n",
    "        <li>K-Nearest Neighbors (KNeighbors)</li>\n",
    "        <li>Stochastic Gradient Descent (SGDC)</li>\n",
    "        <li>Support Vector Machines (SVM)</li>\n",
    "        <li>Logistic Regression</li>\n",
    "     </ul>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "312653df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score ,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa9188e",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "735f4667-513c-4315-8906-9838753cfed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-57 {color: black;background-color: white;}#sk-container-id-57 pre{padding: 0;}#sk-container-id-57 div.sk-toggleable {background-color: white;}#sk-container-id-57 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-57 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-57 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-57 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-57 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-57 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-57 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-57 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-57 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-57 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-57 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-57 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-57 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-57 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-57 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-57 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-57 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-57 div.sk-item {position: relative;z-index: 1;}#sk-container-id-57 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-57 div.sk-item::before, #sk-container-id-57 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-57 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-57 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-57 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-57 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-57 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-57 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-57 div.sk-label-container {text-align: center;}#sk-container-id-57 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-57 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-57\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;gaussiannb&#x27;, GaussianNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-169\" type=\"checkbox\" ><label for=\"sk-estimator-id-169\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;gaussiannb&#x27;, GaussianNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-170\" type=\"checkbox\" ><label for=\"sk-estimator-id-170\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-171\" type=\"checkbox\" ><label for=\"sk-estimator-id-171\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('gaussiannb', GaussianNB())])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian = make_pipeline(preprocessing.StandardScaler(),GaussianNB())\n",
    "gaussian.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e7e2a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = gaussian.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "644142ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.69      0.30      0.42        30\n",
      "         yes       0.76      0.94      0.84        69\n",
      "\n",
      "    accuracy                           0.75        99\n",
      "   macro avg       0.72      0.62      0.63        99\n",
      "weighted avg       0.74      0.75      0.71        99\n",
      "\n",
      "Confusion matrix \n",
      " [[ 9 21]\n",
      " [ 4 65]]\n",
      "accuracy_Naive Bayes: 0.747\n"
     ]
    }
   ],
   "source": [
    "accuracy_nb=round(accuracy_score(y_test,Y_pred)* 100, 2)\n",
    "acc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, Y_pred))\n",
    "accuracy_nb=round(accuracy_score(y_test,Y_pred)* 100, 2)\n",
    "acc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\n",
    "\n",
    "cm = confusion_matrix(y_test, Y_pred)\n",
    "accuracy = accuracy_score(y_test,Y_pred)\n",
    "\n",
    "print('Confusion matrix \\n',cm)\n",
    "print('accuracy_Naive Bayes: %.3f' %accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d45b83e",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNeighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f1c97ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "c500327b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.69      0.30      0.42        30\n",
      "         yes       0.76      0.94      0.84        69\n",
      "\n",
      "    accuracy                           0.75        99\n",
      "   macro avg       0.72      0.62      0.63        99\n",
      "weighted avg       0.74      0.75      0.71        99\n",
      "\n",
      "Confusion matrix \n",
      " [[ 9 21]\n",
      " [ 4 65]]\n",
      "accuracy_Knn: 0.687\n"
     ]
    }
   ],
   "source": [
    "knn = make_pipeline(preprocessing.StandardScaler(),KNeighborsClassifier(n_neighbors=5))\n",
    "knn.fit(X_train, y_train)\n",
    "Y_pred4 = knn.predict(X_test) \n",
    "\n",
    "accuracy1 = accuracy_score(y_test,Y_pred4)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, Y_pred))\n",
    "accuracy_nb=round(accuracy_score(y_test,Y_pred)* 100, 2)\n",
    "acc_gaussian = round(knn.score(X_train, y_train) * 100, 2)\n",
    "\n",
    "cm1 = confusion_matrix(y_test, Y_pred)\n",
    "\n",
    "\n",
    "print('Confusion matrix \\n',cm1)\n",
    "print('accuracy_Knn: %.3f' %accuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e5fb0c",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "b0f02a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d7d5e97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.69      0.30      0.42        30\n",
      "         yes       0.76      0.94      0.84        69\n",
      "\n",
      "    accuracy                           0.75        99\n",
      "   macro avg       0.72      0.62      0.63        99\n",
      "weighted avg       0.74      0.75      0.71        99\n",
      "\n",
      "Confusion matrix \n",
      " [[ 9 21]\n",
      " [15 54]]\n",
      "accuracy_Naive Bayes: 0.636\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(StandardScaler(),\n",
    "                     SGDClassifier(penalty='l2', alpha=0.0001))\n",
    "\n",
    "sgd.fit(X_train, y_train)\n",
    "Y_pred7 = sgd.predict(X_test) \n",
    "\n",
    "print(classification_report(y_test, Y_pred))\n",
    "accuracy_nb=round(accuracy_score(y_test,Y_pred7)* 100, 2)\n",
    "acc_gaussian = round(sgd.score(X_train, y_train) * 100, 2)\n",
    "\n",
    "cm3 = confusion_matrix(y_test, Y_pred7)\n",
    "accuracy2 = accuracy_score(y_test,Y_pred7)\n",
    "\n",
    "print('Confusion matrix \\n',cm3)\n",
    "print('accuracy_Naive Bayes: %.3f' %accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfce33a",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "7a607665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "441a2306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier_SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.69      0.30      0.42        30\n",
      "         yes       0.76      0.94      0.84        69\n",
      "\n",
      "    accuracy                           0.75        99\n",
      "   macro avg       0.72      0.62      0.63        99\n",
      "weighted avg       0.74      0.75      0.71        99\n",
      "\n",
      "Confusion matrix \n",
      " [[ 9 21]\n",
      " [ 4 65]]\n",
      "accuracy_SVM: 0.707\n"
     ]
    }
   ],
   "source": [
    "svc = make_pipeline(preprocessing.StandardScaler(),SVC(C=1))\n",
    "svc.fit(X_train, y_train)\n",
    "Y_pred1 = svc.predict(X_test) \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('SGD Classifier_SVM')\n",
    "print(classification_report(y_test, Y_pred))\n",
    "accuracy_nb=round(accuracy_score(y_test,Y_pred)* 100, 2)\n",
    "acc_gaussian = round(svc.score(X_train, y_train) * 100, 2)\n",
    "\n",
    "cm2 = confusion_matrix(y_test, Y_pred)\n",
    "accuracy3 = accuracy_score(y_test,Y_pred1)\n",
    "\n",
    "print('Confusion matrix \\n',cm1)\n",
    "print('accuracy_SVM: %.3f' %accuracy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61efadd8",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "773d4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "6236d046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.56      0.30      0.39        30\n",
      "         yes       0.75      0.90      0.82        69\n",
      "\n",
      "    accuracy                           0.72        99\n",
      "   macro avg       0.65      0.60      0.60        99\n",
      "weighted avg       0.69      0.72      0.69        99\n",
      "\n",
      "Confusion matrix \n",
      " [[ 9 21]\n",
      " [ 7 62]]\n",
      "accuracy_Logistic Regression: 0.747\n"
     ]
    }
   ],
   "source": [
    "Logistic = make_pipeline(preprocessing.StandardScaler(),LogisticRegression(multi_class='multinomial'))\n",
    "Logistic.fit(X_train, y_train)\n",
    "\n",
    "Y_pred3 = Logistic.predict(X_test) \n",
    "\n",
    "print('Logistic Regression')\n",
    "print(classification_report(y_test, Y_pred3))\n",
    "accuracy_nb=round(accuracy_score(y_test,Y_pred3)* 100, 2)\n",
    "acc_gaussian = round(Logistic.score(X_train, y_train) * 100, 2)\n",
    "\n",
    "cm = confusion_matrix(y_test, Y_pred3)\n",
    "accuracy4 = accuracy_score(y_test,Y_pred)\n",
    "\n",
    "print('Confusion matrix \\n',cm)\n",
    "print('accuracy_Logistic Regression: %.3f' %accuracy4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fc6694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b43679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
