{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f5e5d5-7cc9-4dc4-8d4a-8cca2ba1bd63",
   "metadata": {},
   "source": [
    "در صورت وجود همبستگی زیاد بین دو فیچر بیشترین تاثیر منفی بر کدام یک از مدل های کلاسبک است\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a397a5-dc4d-421f-aec1-88a4838a1945",
   "metadata": {},
   "source": [
    "1-Linear models (e.g., linear regression or logistic regression), multicolinearity can yield solutions that are wildly varying and possibly numerically unstable.<br>\n",
    "2-Random forests can be good at detecting interactions between different features, but highly correlated features can mask these interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e324666-32d3-4af9-86d7-e870599650df",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb4cd6c-fe75-4235-9f36-f5e0ae762d97",
   "metadata": {},
   "source": [
    "نوشته و برای پیدا کردن آن ها از کدام فانکشن در کد استفاده میشود percision و recallفرمول "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f0c8b1-3dce-488b-bc2b-7a984497c1c5",
   "metadata": {},
   "source": [
    "Recall = TruePositives / (TruePositives + FalseNegatives) <br>\n",
    "recall_score()<br>\n",
    "Precision = TruePositives / (TruePositives + FalsePositives) <br>\n",
    "precision_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d097f2-43f3-4730-bd4d-e4d9ddd2b99c",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d9654e-8278-4fa4-bc2b-7a8b1c8102b2",
   "metadata": {},
   "source": [
    "چیست و کدام یک معادل ریکال است roc curveدو پارامتر مهم در  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36057aa2-32ca-4ff4-85b4-ef10f695904a",
   "metadata": {},
   "source": [
    "True Positive Rate (TPR) is a synonym for recall and False Positive Rate (FPR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d536955-6a02-4303-b7cb-73fbf24237f6",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f19984-7836-45c8-b24f-9a76e27c66e7",
   "metadata": {},
   "source": [
    " چیستaucمنظور از  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db22171-4b4c-4d68-80a9-9af23e87140e",
   "metadata": {},
   "source": [
    "auc : area under the curve <br>\n",
    "AUC provides an aggregate measure of performance across all possible classification thresholds. One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfdd528-49d3-4bc3-8164-e4db3ffbcf33",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3befcf-f45a-4c94-b318-2c95bbf50b46",
   "metadata": {},
   "source": [
    "را نام ببرید و به طور کلی کرنل در این مدل یعنی انجام چه کاری؟svm kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61ba581-090f-43cd-9bc2-f288606d5e1d",
   "metadata": {},
   "source": [
    "Polynomial kernel<br>\n",
    "RBF kernel<br>\n",
    "linrear Kernel<br>\n",
    "When using SVMs you can apply an almost miraculous mathematical\n",
    "technique called the kernel trick. The kernel trick makes it\n",
    "possible to get the same result as if you had added many polynomial features, even\n",
    "with very high-degree polynomials, without actually having to add them. So there is\n",
    "no combinatorial explosion of the number of features because you don’t actually add\n",
    "any features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6329a1-d31b-4dc0-b07f-a07362347873",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e125274-fdd0-4595-bad9-c6ed748034b7",
   "metadata": {},
   "source": [
    "را می خواهیم پیاده سازی کنیم همانطور که میبیتید نسبت دیتاها بسیار متفاوت است چه راه حلی را پیشتهاد میکنید  svcدر دیتاستی ۱۰۰۰ داده با لیبل ۱ و ۲۰ داده با لیبل ۲ وجود دارد میخواهیم بر روی این دیتا مدل "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff976c-ea64-40d2-ac5f-b2c614a34e18",
   "metadata": {},
   "source": [
    " Weighted SVM: the simplest and most common extension to SVM for imbalanced classification is to weight the C value in proportion to the importance of each class.<br>\n",
    " C_i = weight_i * C <br>\n",
    " Small Weight: Smaller C value, larger penalty for misclassified examples.<br>\n",
    "Larger Weight: Larger C value, smaller penalty for misclassified examples.<br>\n",
    "model = SVC(gamma='scale', class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c556e7f-b6d7-40ec-8b5a-7fec5a66c6e4",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18852940-7c1c-437a-a329-7f20f5589438",
   "metadata": {},
   "source": [
    "زیر برقرار است عدد ۲ و عدد ۳ چه مفهومی را می رساند  confusion matrix بر روی داده های پیش بینی شده توسط یک مدل و لیبل های واقعی آن "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7399440-cc1b-4c3a-ad03-aa004c49737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[10  2 0]\n",
    " [ 0  8  3]\n",
    " [ 0  0 11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c1530-7066-4526-9b2f-8f6cd026eabc",
   "metadata": {},
   "source": [
    "this confusion matrix is for a data set with 3 labels and 2 and 3 are the false negetive and 10, 8 and 11 are the true positive "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be8e03d-a72f-4c3c-a69a-52ffd4c58298",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee396c07-99d7-4c2e-bf31-93dca02e1b1d",
   "metadata": {},
   "source": [
    "کنیم چه روش هایی را استفاده میکنید model-base   الگوریتم است برای اینکه این الگوریتم را کمی شبیه الگوریتم هایinstance-base یک knn الگوریتم"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b3a803-89f9-4949-9667-32d382ce96ed",
   "metadata": {},
   "source": [
    "1- We can integrated KNN and constrained logistic regression (KNNLog) approach for sparsef parametric estimation, which forces the irrelevant features to zero.<br>\n",
    "2- There are also algorithm used to compute the nearest neighbors:<br>\n",
    "‘ball_tree’ will use BallTree<br>\n",
    "‘kd_tree’ will use KDTree<br>\n",
    "‘brute’ will use a brute-force search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f242886-adc5-4c69-bae4-2c95e177983c",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b44a13-a736-4af8-8219-205bc5400990",
   "metadata": {},
   "source": [
    "را امتحان کنید svmروی دیتای زیر پارامترهای الگوریتم مناسب   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ae84116-304b-4c09-934c-9fa814525d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c33c88-480f-4be5-90e9-be29b39fd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0830ab01-3417-4f80-93b9-7454014e2c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  target  \n",
       "0                            3.92   1065.0     0.0  \n",
       "1                            3.40   1050.0     0.0  \n",
       "2                            3.17   1185.0     0.0  \n",
       "3                            3.45   1480.0     0.0  \n",
       "4                            2.93    735.0     0.0  \n",
       "..                            ...      ...     ...  \n",
       "173                          1.74    740.0     2.0  \n",
       "174                          1.56    750.0     2.0  \n",
       "175                          1.56    835.0     2.0  \n",
       "176                          1.62    840.0     2.0  \n",
       "177                          1.60    560.0     2.0  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(data=np.c_[wine['data'],wine['target']],columns=wine['feature_names']+['target'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47b88607-6ca4-4b1e-8b16-86cf3cbb3bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abd4535b-745a-4178-93a0-b94b930caa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis = 1).values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51943dd3-28db-4ea0-80dc-f9879a1f551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6cb5ee4-6379-4417-8552-7aca2056d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0100f08f-94b2-4bd9-9b4d-962b8f1c711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = make_pipeline(StandardScaler(), SVC())\n",
    "svc_model.fit(X_train, y_train)\n",
    "y_pred = svc_model.predict(X_test)\n",
    "svc_model_acc = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b03a46e-06ba-4985-905f-f70cb1bbbfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814814814814815"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666af34-d162-40d2-967d-2768b35dfeff",
   "metadata": {},
   "source": [
    "## linux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea5d7d-3982-47ab-9d3f-622b5444c13f",
   "metadata": {},
   "source": [
    "چند دیستربیوشن مهم لینوکس دز دنیای امروز را نام ببرید و منظور از کرنل چیست"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8774ef1-a686-499a-8bbe-764c1f00f24f",
   "metadata": {},
   "source": [
    "\n",
    "There are three main “families” of Linux distributions: Debian, Red Hat, and SUSE. Most other Linux distributions use one of these three distributions as their foundation.<br>\n",
    "Kernel: The Linux kernel is the main component of a Linux operating system (OS) and is the core interface between a computer’s hardware and its processes. It communicates between the 2, managing resources as efficiently as possible.\n",
    "The kernel is so named because—like a seed inside a hard shell—it exists within the OS and controls all the major functions of the hardware, whether it’s a phone, laptop, server, or any other kind of computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7189ab6-b42a-491b-96f3-5892b8e07b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
