{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c31b86-dc76-4f81-bfa1-8d212ff81f54",
   "metadata": {},
   "source": [
    "<div dir = \"rtl\" style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=6 color=#F32500>\n",
    "        <div  align=center>\n",
    "            تمرین هفته دهم بوت کمپ یادگیری ماشین-\n",
    "            مپصا\n",
    "        </div>\n",
    "        <br/>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f383f6fe-a565-4990-82c6-dfbab8a0002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and libraries here.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier,Perceptron,LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay , accuracy_score\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e3c3a8-c6b3-4277-96db-ec4b30a051b3",
   "metadata": {},
   "source": [
    "# 1- State with reasons whether the following sentences are true or false?\n",
    "\n",
    "<ul style=\"font-size:25px\">\n",
    "    <li>\n",
    "        SVMs are not suitable for large datasets.\n",
    "    </li>\n",
    "    <li>\n",
    "       SVMs perform poorly in imbalanced datasets.\n",
    "    </li>\n",
    "     <li>\n",
    "        SVMs perform poorly when there is just too much noise in the data.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7eb499",
   "metadata": {},
   "source": [
    "SVMs are not suitable for large datasets.\n",
    "The original SVM implementation is known to have a concrete theoretical foundation, but it is not suitable for classifying in large datasets for one straightforward reason — the complexity of the algorithm’s training is highly dependent on the size of the dataset. In other words, training time grows with the dataset to a point where it becomes infeasible to train and use due to compute constraints.\n",
    "On the bright side, there have been several advancements to the SVM since its original implementation by AT&T Bell Laboratories back in 1992 [1]. Training SVMs are much more scalable with dataset sizes nowadays.\n",
    "\n",
    "SVMs perform poorly in imbalanced datasets.\n",
    "There are two more well-attributed reasons [2] for this. The first being the weakness of the soft margin optimization problem. This results in the hyperplanes being skewed to the minority class when imbalanced data is used for training.\n",
    "The second reason arises from the issue of an imbalanced support vector ratio, i.e. the ratio between the positive and negative support vectors becoming imbalanced and as a result, datapoints at the decision boundaries of the hyperplanes have a higher chance of being classified as negative.\n",
    "There are however approaches to reduce this impact. One of the more commonly used approaches is to introduce class weights, so the magnitude of the positive support will be proportionately higher than that of the negative support vector. Class weights are used in other machine learning algorithms as well, when training with imbalanced datasets.\n",
    "\n",
    "\n",
    "SVMs perform poorly when there is just too much noise in the data.\n",
    "In these cases of noisy data, target classes are overlapping, in the sense that the features can have very similar or overlapping properties. This possibly results in arriving at several local optima due to the nature of the optimization algorithm, especially for high dimensional datasets.\n",
    "However, it is worthwhile to note that noise should not be the problem for kernels with high-bias, such as the linear and polynomial kernels. The issue of noise should lie more for the low-bias kernels such as the radial basis function (RBF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4eb95-8d60-4d68-a859-5d7007178d0f",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t ۲- دیتاست lsvt-voice-rehabilitation را از لینک زیر دانلود کنید و به سوالات زیر حواب دهید. در این تمرین مجاز به استفاده از کتابخانه scikit-learn می باشید.\n",
    "\t\t</br>\n",
    "</div>\n",
    "\t\thttps://archive.ics.uci.edu/ml/datasets/LSVT+Voice+Rehabilitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e572a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 310)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('LSVT_voice_rehabilitation.xlsx', sheet_name='Data')\n",
    "Br = pd.read_excel('LSVT_voice_rehabilitation.xlsx', sheet_name='Binary response')\n",
    "Sr = pd.read_excel('LSVT_voice_rehabilitation.xlsx', sheet_name='Subject demographics')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8d4f4953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    309\n",
       "int64        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4237770b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Br.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "90edf077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Br.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "54e4348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.values\n",
    "y=Br.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d86ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cdb4b5-e80e-41db-b3a5-e495247bb679",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t الف- داده ها را به روشهای زیر دسته بندی کنید (حواستان باشد که داده ها را قبل از اعمال به مدل، نرمالایز کنید).\n",
    "        <ul>\n",
    "            <li>\n",
    "            کرنل خطی\n",
    "            </li>\n",
    "            <li>\n",
    "            کرنل چندجمله ای (پارامترهای r, d)\n",
    "            </li>\n",
    "            <li>\n",
    "            کرنل rbf - پارامتر گاما\n",
    "            </li>\n",
    "            <li>\n",
    "            سیگمویید - پارامتر r\n",
    "            </li>           \n",
    "         </ul>\n",
    "</div"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e07bd9",
   "metadata": {},
   "source": [
    "# linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4eca7bc3-3d65-46a2-8cb2-333d46472d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67         6\n",
      "           2       1.00      0.70      0.82        20\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.75      0.85      0.75        26\n",
      "weighted avg       0.88      0.77      0.79        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_svm_linear = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='linear'))\n",
    "svc_svm_linear.fit(X_train, y_train)\n",
    "y_predict_svc_svm_linear= svc_svm_linear.predict(X_test)\n",
    "print(classification_report(y_test,y_predict_svc_svm_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2900fbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67         6\n",
      "           2       1.00      0.70      0.82        20\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.75      0.85      0.75        26\n",
      "weighted avg       0.88      0.77      0.79        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_svm_linear = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='linear',gamma=0.0001,coef0=1))\n",
    "svc_svm_linear.fit(X_train, y_train)\n",
    "y_predict_svc_svm_linear= svc_svm_linear.predict(X_test)\n",
    "print(classification_report(y_test,y_predict_svc_svm_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "decdfce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67         6\n",
      "           2       1.00      0.70      0.82        20\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.75      0.85      0.75        26\n",
      "weighted avg       0.88      0.77      0.79        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_svm_linear = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='linear',coef0=0.00001,degree=10,tol=0.0001))\n",
    "svc_svm_linear.fit(X_train, y_train)\n",
    "y_predict_svc_svm_linear= svc_svm_linear.predict(X_test)\n",
    "print(classification_report(y_test,y_predict_svc_svm_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b31ccf",
   "metadata": {},
   "source": [
    "# poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "09929746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.77      1.00      0.87        20\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.38      0.50      0.43        26\n",
      "weighted avg       0.59      0.77      0.67        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc_svm_poly = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='poly'))\n",
    "svc_svm_poly.fit(X_train, y_train)\n",
    "y_predict_svc_svm_poly= svc_svm_poly.predict(X_test)\n",
    "print(classification_report(y_test,y_predict_svc_svm_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4b5e643a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.77      1.00      0.87        20\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.38      0.50      0.43        26\n",
      "weighted avg       0.59      0.77      0.67        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc_svm_poly = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='poly',gamma=0.0001,coef0=1))\n",
    "svc_svm_poly.fit(X_train, y_train)\n",
    "y_predict_svc_svm_poly= svc_svm_poly.predict(X_test)\n",
    "print(classification_report(y_test,y_predict_svc_svm_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "db05d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.77      1.00      0.87        20\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.38      0.50      0.43        26\n",
      "weighted avg       0.59      0.77      0.67        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc_svm_poly = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='poly',coef0=0.1,degree=10,tol=0.01))\n",
    "svc_svm_poly.fit(X_train, y_train)\n",
    "y_predict_svc_svm_poly= svc_svm_poly.predict(X_test)\n",
    "print(classification_report(y_test,y_predict_svc_svm_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ef2e4",
   "metadata": {},
   "source": [
    "# rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "36ed16ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.77      1.00      0.87        20\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.38      0.50      0.43        26\n",
      "weighted avg       0.59      0.77      0.67        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc_svm_rbf = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='rbf',gamma=10))\n",
    "svc_svm_rbf.fit(X_train, y_train)\n",
    "y_predict_svc_svm_rbf= svc_svm_rbf.predict(X_test)\n",
    "print(classification_report(y_test,y_predict_svc_svm_rbf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a95130f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.77      1.00      0.87        20\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.38      0.50      0.43        26\n",
      "weighted avg       0.59      0.77      0.67        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc_svm_rbf = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='rbf',gamma=0.0001,coef0=1))\n",
    "svc_svm_rbf.fit(X_train, y_train)\n",
    "y_predict_svc_svm_rbf= svc_svm_rbf.predict(X_test)\n",
    "print(classification_report(y_test,y_predict_svc_svm_rbf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "41caa126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.77      1.00      0.87        20\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.38      0.50      0.43        26\n",
      "weighted avg       0.59      0.77      0.67        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cmos/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc_svm_rbf = make_pipeline(preprocessing.StandardScaler(),SVC(C=0.1,kernel='rbf',gamma=10,coef0=0.00001,degree=10,tol=0.0001))\n",
    "svc_svm_rbf.fit(X_train, y_train)\n",
    "y_predict_svc_svm_rbf= svc_svm_rbf.predict(X_test)\n",
    "print(classification_report(y_test,y_predict_svc_svm_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708127cb",
   "metadata": {},
   "source": [
    "# sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0fe47c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      1.00      0.86         6\n",
      "           2       1.00      0.90      0.95        20\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.88      0.95      0.90        26\n",
      "weighted avg       0.94      0.92      0.93        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_svm_sigmoid = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='sigmoid'))\n",
    "svc_svm_sigmoid.fit(X_train, y_train)\n",
    "y_predict_svc_svm_sigmoid= svc_svm_sigmoid.predict(X_test)\n",
    "print(classification_report(y_test,y_predict_svc_svm_sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f67ace94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.83      0.67         6\n",
      "           2       0.94      0.80      0.86        20\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.75      0.82      0.77        26\n",
      "weighted avg       0.85      0.81      0.82        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_svm_sigmoid = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='sigmoid',C=0.1,gamma=10,coef0=0.00001,degree=10,tol=0.0001))\n",
    "svc_svm_sigmoid.fit(X_train, y_train)\n",
    "y_predict_svc_svm_sigmoid= svc_svm_sigmoid.predict(X_test)\n",
    "print(classification_report(y_test,y_predict_svc_svm_sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1865f976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.67      0.53         6\n",
      "           2       0.88      0.75      0.81        20\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.66      0.71      0.67        26\n",
      "weighted avg       0.78      0.73      0.75        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_svm_sigmoid = make_pipeline(preprocessing.StandardScaler(),SVC(kernel='sigmoid',gamma=100,coef0=1))\n",
    "svc_svm_sigmoid.fit(X_train, y_train)\n",
    "y_predict_svc_svm_sigmoid= svc_svm_sigmoid.predict(X_test)\n",
    "print(classification_report(y_test,y_predict_svc_svm_sigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a7d0b1-9500-4a57-9fd1-5230eb3f9184",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t ب- معیار دقت و f1 را برای هریک از دسته بندی های قسمت الف به دست آورید. (برای هر یک از پارامترهای گفته شده حداقل سه مقدار مختلف در نظر بگیرید)\n",
    "\t\t</br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c09cdec8-3f23-4df7-bbe0-db783eb42343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a6660b-18d8-40ac-b651-f1df747b871f",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t ج- تاثیر پارامترهای هر کرنل را بر کارآیی مدل ها تحلیل کنید.\n",
    "\t\t</br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcddf69d-fe5a-456c-aa31-c6fad547ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "در حالت خطی تغییر پارامتر هیچ تاثیری ندارد"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a212a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "در حالت پلی مدل کلا اندر فیت میشه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "در حالت بی ار اف مدل کلا اندر فیت میشه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a4891",
   "metadata": {},
   "outputs": [],
   "source": [
    "در حالت سیگمود زیاد کردن کاما مناسب نیست"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7201b1-1800-4e9d-ae00-7cb5c9d673c8",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t د- کدام مدل عملکرد بهتری دارد؟ چرا؟\n",
    "\t\t</br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(126, 310)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d6f60c2-09b9-4dc9-b3fb-3d556ef62b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "به نظر من چون تعداد داده ها ۱۲۶ سطر و ستون ها ۳۱۰ تا هست تعداد فیچر های زیاد مدل رو به خودی خود پیچیده کرده \n",
    "کرنل هایی مثل چند جمله ای کامپلکسی یا همان پیچیدگی رو برای این داده ها بالاتر میبره و مدل اندر فیت میشه\n",
    "در مواقعی که خود دیتا دارای پیچیدگی زیاد است همان کرنل های ساده مثل خطی یا سیگمود بهتر جواب میده"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028f455-56e3-489b-94c3-1f77e9460a4d",
   "metadata": {},
   "source": [
    "# 3- Student Intervention System\n",
    "\n",
    "<div style=\"margin-left: 10px;font-size:15px\">a) Run the code cell below to load necessary Python libraries and load the student data. Note that the last column from this dataset, 'passed', will be our target label (whether the student graduated or didn't graduate). All other columns are features about each student.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b3d38d1-e78a-4017-adca-b296225645b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  internet romantic  famrel  freetime  goout Dalc Walc health absences passed  \n",
       "0       no       no       4         3      4    1    1      3        6     no  \n",
       "1      yes       no       5         3      3    1    1      3        4     no  \n",
       "2      yes       no       4         3      2    2    3      3       10    yes  \n",
       "3      yes      yes       3         2      2    1    1      5        2    yes  \n",
       "4       no       no       4         3      2    1    2      5        4    yes  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data = pd.read_csv(\"student_data.csv\")\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd5509-8974-44c8-87c9-06e5aefb475c",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 10px;font-size:15px\">\n",
    "  <p>  \n",
    "b) Let's begin by investigating the dataset to determine how many students we have information on, and learn about the graduation rate among these students. In the code cell below, you will need to compute the following:\n",
    "    </p>\n",
    "    <ul>\n",
    "        <li>The total number of students, n_students.</li>\n",
    "        <li>The total number of features for each student, n_features.</li>\n",
    "        <li>The number of those students who passed, n_passed.</li>\n",
    "        <li>The number of those students who failed, n_failed.</li>\n",
    "        <li>The graduation rate of the class, grad_rate, in percent (%).</li>\n",
    "     </ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75834b0c-fd2a-45ae-bb4b-041b53ea039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of features: 30\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate number of students\n",
    "n_students = student_data.shape[0]\n",
    "\n",
    "# TODO: Calculate number of features\n",
    "n_features = student_data.shape[1]-1\n",
    "\n",
    "# TODO: Calculate passing students\n",
    "n_passed = student_data.loc[student_data[\"passed\"]==\"yes\"].shape[0]\n",
    "\n",
    "# TODO: Calculate failing students\n",
    "n_failed = student_data.loc[student_data[\"passed\"]==\"no\"].shape[0]\n",
    "\n",
    "# TODO: Calculate graduation rate\n",
    "grad_rate = (n_passed/n_students)*100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of students: {}\".format(n_students))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of students who passed: {}\".format(n_passed))\n",
    "print(\"Number of students who failed: {}\".format(n_failed))\n",
    "print(\"Graduation rate of the class: {:.2f}%\".format(grad_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb98764-1eab-402f-a9c6-846417c02d75",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"margin-left: 10px;font-size:15px\">\n",
    "    <p>c) Preparing the Data</p>\n",
    "    <p>In this section, we will prepare the data for modeling, training and testing.</p>\n",
    "    <p>Identify feature and target columns\n",
    "It is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "Run the code cell below to separate the student data into feature and target columns to see if any features are non-numeric.</p>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62d65bfa-7b48-406d-b496-cb27a4db5139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 31 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   school      395 non-null    object\n",
      " 1   sex         395 non-null    object\n",
      " 2   age         395 non-null    int64 \n",
      " 3   address     395 non-null    object\n",
      " 4   famsize     395 non-null    object\n",
      " 5   Pstatus     395 non-null    object\n",
      " 6   Medu        395 non-null    int64 \n",
      " 7   Fedu        395 non-null    int64 \n",
      " 8   Mjob        395 non-null    object\n",
      " 9   Fjob        395 non-null    object\n",
      " 10  reason      395 non-null    object\n",
      " 11  guardian    395 non-null    object\n",
      " 12  traveltime  395 non-null    int64 \n",
      " 13  studytime   395 non-null    int64 \n",
      " 14  failures    395 non-null    int64 \n",
      " 15  schoolsup   395 non-null    object\n",
      " 16  famsup      395 non-null    object\n",
      " 17  paid        395 non-null    object\n",
      " 18  activities  395 non-null    object\n",
      " 19  nursery     395 non-null    object\n",
      " 20  higher      395 non-null    object\n",
      " 21  internet    395 non-null    object\n",
      " 22  romantic    395 non-null    object\n",
      " 23  famrel      395 non-null    int64 \n",
      " 24  freetime    395 non-null    int64 \n",
      " 25  goout       395 non-null    int64 \n",
      " 26  Dalc        395 non-null    int64 \n",
      " 27  Walc        395 non-null    int64 \n",
      " 28  health      395 non-null    int64 \n",
      " 29  absences    395 non-null    int64 \n",
      " 30  passed      395 non-null    object\n",
      "dtypes: int64(13), object(18)\n",
      "memory usage: 95.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# # Extract feature columns\n",
    "# feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# # Extract target column 'passed'\n",
    "# target_col = student_data.columns[-1] \n",
    "\n",
    "# # Show the list of columns\n",
    "# print(\"Feature columns:\\n{}\".format(feature_cols))\n",
    "# print(\"\\nTarget column: {}\".format(target_col))\n",
    "\n",
    "# # Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "# X = student_data[feature_cols]\n",
    "# y = student_data[target_col]\n",
    "\n",
    "# student_data[:-1].dtypes.value_counts()\n",
    "student_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd174d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data= student_data.replace(['no','yes'],[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df1d33dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "       'reason', 'guardian'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mas = student_data.dtypes == 'object'\n",
    "student_data.columns[mas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2edff341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>...</th>\n",
       "      <th>Fjob_other</th>\n",
       "      <th>Fjob_services</th>\n",
       "      <th>Fjob_teacher</th>\n",
       "      <th>reason_course</th>\n",
       "      <th>reason_home</th>\n",
       "      <th>reason_other</th>\n",
       "      <th>reason_reputation</th>\n",
       "      <th>guardian_father</th>\n",
       "      <th>guardian_mother</th>\n",
       "      <th>guardian_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  Medu  Fedu  traveltime  studytime  failures  schoolsup  famsup  \\\n",
       "0     18     4     4           2          2         0          1       0   \n",
       "1     17     1     1           1          2         0          0       1   \n",
       "2     15     1     1           1          2         3          1       0   \n",
       "3     15     4     2           1          3         0          0       1   \n",
       "4     16     3     3           1          2         0          0       1   \n",
       "..   ...   ...   ...         ...        ...       ...        ...     ...   \n",
       "390   20     2     2           1          2         2          0       1   \n",
       "391   17     3     1           2          1         0          0       0   \n",
       "392   21     1     1           1          1         3          0       0   \n",
       "393   18     3     2           3          1         0          0       0   \n",
       "394   19     1     1           1          1         0          0       0   \n",
       "\n",
       "     paid  activities  ...  Fjob_other  Fjob_services  Fjob_teacher  \\\n",
       "0       0           0  ...           0              0             1   \n",
       "1       0           0  ...           1              0             0   \n",
       "2       1           0  ...           1              0             0   \n",
       "3       1           1  ...           0              1             0   \n",
       "4       1           0  ...           1              0             0   \n",
       "..    ...         ...  ...         ...            ...           ...   \n",
       "390     1           0  ...           0              1             0   \n",
       "391     0           0  ...           0              1             0   \n",
       "392     0           0  ...           1              0             0   \n",
       "393     0           0  ...           1              0             0   \n",
       "394     0           0  ...           0              0             0   \n",
       "\n",
       "     reason_course  reason_home  reason_other  reason_reputation  \\\n",
       "0                1            0             0                  0   \n",
       "1                1            0             0                  0   \n",
       "2                0            0             1                  0   \n",
       "3                0            1             0                  0   \n",
       "4                0            1             0                  0   \n",
       "..             ...          ...           ...                ...   \n",
       "390              1            0             0                  0   \n",
       "391              1            0             0                  0   \n",
       "392              1            0             0                  0   \n",
       "393              1            0             0                  0   \n",
       "394              1            0             0                  0   \n",
       "\n",
       "     guardian_father  guardian_mother  guardian_other  \n",
       "0                  0                1               0  \n",
       "1                  1                0               0  \n",
       "2                  0                1               0  \n",
       "3                  0                1               0  \n",
       "4                  1                0               0  \n",
       "..               ...              ...             ...  \n",
       "390                0                0               1  \n",
       "391                0                1               0  \n",
       "392                0                0               1  \n",
       "393                0                1               0  \n",
       "394                1                0               0  \n",
       "\n",
       "[395 rows x 49 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data = pd.get_dummies(student_data, columns=student_data.columns[mas], drop_first=False)\n",
    "student_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a82fa-9a11-4ad5-8ed1-e61086fa3874",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 10px;font-size:15px\">\n",
    "    <p>d) Preprocess Feature Columns</p>\n",
    "    <p>As you can see, there are several non-numeric columns that need to be converted! Many of them are simply yes/no, e.g. internet. These can be reasonably converted into 1/0 (binary) values.</p>\n",
    "    <p>\n",
    "Other columns, like Mjob and Fjob, have more than two values, and are known as categorical variables. The recommended way to handle such a column is to create as many columns as possible values (e.g. Fjob_teacher, Fjob_other, Fjob_services, etc.), and assign a 1 to one of them and 0 to all others.\n",
    "\n",
    "These generated columns are sometimes called dummy variables, and we will use the pandas.get_dummies() function to perform this transformation. Run the code cell below to perform the preprocessing routine discussed in this section.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37fa60c9-b048-443a-8833-3717c637f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the student data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.items():\n",
    "\n",
    "        # If data type is non-numeric, replace all binary values with 1/0\n",
    "        if col_data.dtype == object and len(col_data.unique()) == 2:\n",
    "            print(\"*****binary*****\")\n",
    "            print(\"col name: \", col, end=\"----\")\n",
    "            col_data_unique = col_data.unique()\n",
    "            print(\"unique values: \", col_data_unique)\n",
    "            col_data = col_data.replace(col_data_unique, [1, 0])\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object and len(col_data.unique()) != 2:\n",
    "            print(\"*****categorical*****\")\n",
    "            print(\"col name: \", col, end=\"----\")\n",
    "            col_data_unique = col_data.unique()\n",
    "            print(\"unique values: \", col_data_unique)\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# X_preprocessed = preprocess_features(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730323a6-decd-4da0-9f56-d15cb7126fe1",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 10px;font-size:15px\">\n",
    "    <p>e) Training and Testing Data Split</p>\n",
    "    <p>split the data (both features and corresponding labels) into training and test sets.(Use 300 training points (approximately 75%) and 95 testing points (approximately 25%).)</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d854097-e759-4d75-aa94-d02bdd5a017c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 48), (43, 48))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Import any additional functionality you may need here\n",
    "from sklearn.model_selection import train_test_split\n",
    "sclra = StandardScaler()\n",
    "X_norm = sclra.fit_transform(X)\n",
    "\n",
    "\n",
    "X = student_data.drop('passed', axis=1)\n",
    "y = student_data['passed']\n",
    "# TODO: split the dataset into the number of training and testing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=43, random_state=42)\n",
    "sclr = StandardScaler()\n",
    "x_train_norm = sclr.fit_transform(x_train)\n",
    "x_test_norm = sclr.transform(x_test)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba84511-5161-437b-9ae1-625aaaed87e6",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 10px;font-size:15px\">\n",
    "<p>f) In this section, you will choose 3 supervised learning models that are appropriate for this problem and available in scikit-learn. You will first discuss the reasoning behind choosing these three models by considering what you know about the data and each model's strengths and weaknesses. You will then fit the model to training data and measure the F1 score. You will need to produce three tables (one for each model) that shows the training set size, training time, prediction time, F1 score on the training set, and F1 score on the testing set.</p>\n",
    "<p>The following supervised learning models are currently available in scikit-learn that you may choose from:</p>\n",
    "    <ul>\n",
    "        <li>Gaussian Naive Bayes (GaussianNB)</li>\n",
    "        <li>K-Nearest Neighbors (KNeighbors)</li>\n",
    "        <li>Stochastic Gradient Descent (SGDC)</li>\n",
    "        <li>Support Vector Machines (SVM)</li>\n",
    "        <li>Logistic Regression</li>\n",
    "     </ul>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a89519",
   "metadata": {},
   "source": [
    "رگرسیون لاجستیک میتونه خوب باشه چون وای پردیکت کلاسیفیکیشن از نوع صفر و یک هستند و این روش برای تشخیص تقلب دانش اموزان میتونه خوب باشه\n",
    "\n",
    "چون وای پردیکت کلاسیفیکیشن از نوع صفر و یک هستند اس وی سی با یه ابر صفحه داده ها رو به راحتی به دو قسمت تبدیل میکنه و میتونه برای این داده ها خوب باشه \n",
    "\n",
    "کی ان ان برای داده هایی خوبه که راجع بهشون اطلاعات کافی داریم و فاصله های بین داده ها هم دقیق باشه و هم مفهوم دار. در مورد نمرات دانش اموزان این مسایل صدق میکنه و میتونه مدل  خوبی بشه "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f391320b",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b5817e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb\n",
      "size train (352, 48) size test (43, 48)\n",
      "Execution time _train_nb: 0.008 seconds\n",
      "Execution time_test_nb: 0.004 seconds\n",
      "f1_score =  0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"nb\")\n",
    "print(\"size train\",x_train.shape,\"size test\", x_test.shape)\n",
    "st = time.time()\n",
    "\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "et = time.time()\n",
    "elapsed_time_train_nb = et - st\n",
    "print('Execution time _train_nb:', round(elapsed_time_train_nb,3), 'seconds')\n",
    "st = time.time()\n",
    "\n",
    "y_predict_nb_clf= nb_clf.predict(X_test)\n",
    "\n",
    "et = time.time()\n",
    "elapsed_time_test_nb = et - st\n",
    "print('Execution time_test_nb:', round(elapsed_time_test_nb,3), 'seconds')\n",
    "\n",
    "print('f1_score = ',f1_score(y_test, y_predict_nb_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce1536c",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4880f953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "size train (352, 48) size test (43, 48)\n",
      "Execution time _train_KNN: 0.011 seconds\n",
      "Execution time_test_KNN: 0.013 seconds\n",
      "f1_score =  0.8125\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN\")\n",
    "print(\"size train\",x_train.shape,\"size test\", x_test.shape)\n",
    "st = time.time()\n",
    "\n",
    "nn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "et = time.time()\n",
    "elapsed_time_train_KNN = et - st\n",
    "print('Execution time _train_KNN:', round(elapsed_time_train_KNN,3), 'seconds')\n",
    "st = time.time()\n",
    "\n",
    "y_predict_knn_clf= knn_clf.predict(X_test)\n",
    "\n",
    "et = time.time()\n",
    "elapsed_time_test_KNN = et - st\n",
    "print('Execution time_test_KNN:', round(elapsed_time_test_KNN,3), 'seconds')\n",
    "\n",
    "print('f1_score = ',f1_score(y_test, y_predict_knn_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef8d56",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "058b94da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier_SVM\n",
      "size train (352, 48) size test (43, 48)\n",
      "Execution time _train_SGD: 0.022 seconds\n",
      "Execution time_test_KNN: 0.005 seconds\n",
      "f1_score =  0.6779661016949153\n"
     ]
    }
   ],
   "source": [
    "print(\"SGD Classifier_SVM\")\n",
    "print(\"size train\",x_train.shape,\"size test\", x_test.shape)\n",
    "st = time.time()\n",
    "\n",
    "sgd_classifier = make_pipeline(StandardScaler(),SGDClassifier(loss=\"hinge\", penalty=\"l2\"))\n",
    "sgd_classifier.fit(X_train, y_train)\n",
    "\n",
    "et = time.time()\n",
    "elapsed_time_train_SGD = et - st\n",
    "print('Execution time _train_SGD:', round(elapsed_time_train_SGD,3), 'seconds')\n",
    "st = time.time()\n",
    "\n",
    "y_predict_sgd= sgd_classifier.predict(X_test)\n",
    "\n",
    "et = time.time()\n",
    "elapsed_time_test_KNN = et - st\n",
    "\n",
    "print('Execution time_test_KNN:', round(elapsed_time_test_KNN,3), 'seconds')\n",
    "\n",
    "print('f1_score = ',f1_score(y_test, y_predict_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f704992e",
   "metadata": {},
   "source": [
    "# Support Vector Machines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a56d7b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc\n",
      "size train (352, 48) size test (43, 48)\n",
      "Execution time _train_svc: 0.094 seconds\n",
      "Execution time_test_svc: 0.004 seconds\n",
      "f1_score =  0.7719298245614034\n"
     ]
    }
   ],
   "source": [
    "print(\"svc\")\n",
    "print(\"size train\",x_train.shape,\"size test\", x_test.shape)\n",
    "st = time.time()\n",
    "\n",
    "svc_classifier = make_pipeline(StandardScaler(),SVC(class_weight='balanced', probability=True))\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "\n",
    "et = time.time()\n",
    "elapsed_time_train_svc = et - st\n",
    "print('Execution time _train_svc:', round(elapsed_time_train_svc,3), 'seconds')\n",
    "st = time.time()\n",
    "\n",
    "y_predict_svc= svc_classifier.predict(X_test)\n",
    "\n",
    "et = time.time()\n",
    "elapsed_time_test_svc = et - st\n",
    "print('Execution time_test_svc:', round(elapsed_time_test_svc,3), 'seconds')\n",
    "\n",
    "print('f1_score = ',f1_score(y_test, y_predict_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef0438",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ae34f118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "size train (352, 48) size test (43, 48)\n",
      "Execution time _train_Logistic: 0.128 seconds\n",
      "Execution time_test_Logistic: 0.004 seconds\n",
      "f1_score =  0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression\")\n",
    "print(\"size train\",x_train.shape,\"size test\", x_test.shape)\n",
    "st = time.time()\n",
    "\n",
    "lm_classifier = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "lm_classifier.fit(X_train, y_train)\n",
    "\n",
    "et = time.time()\n",
    "elapsed_time_train_Logistic = et - st\n",
    "print('Execution time _train_Logistic:', round(elapsed_time_train_Logistic,3), 'seconds')\n",
    "st = time.time()\n",
    "\n",
    "y_predict_LogisticRegression= lm_classifier.predict(X_test)\n",
    "\n",
    "et = time.time()\n",
    "elapsed_time_test_Logistic = et - st\n",
    "print('Execution time_test_Logistic:', round(elapsed_time_test_Logistic,3), 'seconds')\n",
    "\n",
    "print('f1_score = ',f1_score(y_test, y_predict_LogisticRegression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "به ترتیب\n",
    "knn\n",
    "SVC\n",
    "logi\n",
    "خوب هستن\n",
    "به ترتیبی که گفته شد هم در زمان هم در اف وان اسکور خوب هستند"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b98514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
