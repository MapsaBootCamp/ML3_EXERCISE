{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c31b86-dc76-4f81-bfa1-8d212ff81f54",
   "metadata": {},
   "source": [
    "<div dir = \"rtl\" style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=6 color=#F32500>\n",
    "        <div  align=center>\n",
    "            تمرین هفته دهم بوت کمپ یادگیری ماشین-\n",
    "            مپصا\n",
    "        </div>\n",
    "        <br/>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f383f6fe-a565-4990-82c6-dfbab8a0002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and libraries here.\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e3c3a8-c6b3-4277-96db-ec4b30a051b3",
   "metadata": {},
   "source": [
    "# 1- State with reasons whether the following sentences are true or false?\n",
    "\n",
    "<ul style=\"font-size:25px\">\n",
    "    <li>\n",
    "        SVMs are not suitable for large datasets.\n",
    "    </li>\n",
    "    <li>\n",
    "       SVMs perform poorly in imbalanced datasets.\n",
    "    </li>\n",
    "     <li>\n",
    "        SVMs perform poorly when there is just too much noise in the data.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "442c2093",
   "metadata": {},
   "source": [
    "1-  The training time complexity is usually between O(m2 × n) and O(m3 × n). Unfortunately, this means that it gets dreadfully slow when the number of training instances gets large"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb2870ef",
   "metadata": {},
   "source": [
    "1- weakness of the soft margin optimization problem. This results in the hyperplanes being skewed to the minority class when imbalanced data is used for training\n",
    "2- he ratio between the positive and negative support vectors becoming imbalanced and as a result, datapoints at the decision boundaries of the hyperplanes have a higher chance of being classified as negative"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8622c4b",
   "metadata": {},
   "source": [
    "1- it is not a problem when you use kernels such as linear and polynomial BUT when use RBF can be affected\n",
    "2- In these cases of noisy data, target classes are overlapping, in the sense that the features can have very similar or overlapping properties. This possibly results in arriving at several local optima due to the nature of the optimization algorithm, especially for high dimensional datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4eb95-8d60-4d68-a859-5d7007178d0f",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t ۲- دیتاست lsvt-voice-rehabilitation را از لینک زیر دانلود کنید و به سوالات زیر حواب دهید. در این تمرین مجاز به استفاده از کتابخانه scikit-learn می باشید.\n",
    "\t\t</br>\n",
    "</div>\n",
    "\t\thttps://archive.ics.uci.edu/ml/datasets/LSVT+Voice+Rehabilitation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cdb4b5-e80e-41db-b3a5-e495247bb679",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t الف- داده ها را به روشهای زیر دسته بندی کنید (حواستان باشد که داده ها را قبل از اعمال به مدل، نرمالایز کنید).\n",
    "        <ul>\n",
    "            <li>\n",
    "            کرنل خطی\n",
    "            </li>\n",
    "            <li>\n",
    "            کرنل چندجمله ای (پارامترهای r, d)\n",
    "            </li>\n",
    "            <li>\n",
    "            کرنل rbf - پارامتر گاما\n",
    "            </li>\n",
    "            <li>\n",
    "            سیگمویید - پارامتر r\n",
    "            </li>           \n",
    "         </ul>\n",
    "</div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4eca7bc3-3d65-46a2-8cb2-333d46472d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X=pd.read_excel('LSVT_voice_rehabilitation.xlsx')\n",
    "Y=pd.read_excel('LSVT_voice_rehabilitation.xlsx',sheet_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f67919b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "total={}\n",
    "def accuracy(data,algorithm):\n",
    "    accuracyscore=[]\n",
    "    f1=[]\n",
    "    for i in range (len(data)-1):\n",
    "        accuracyscore.append(accuracy_score(data[-1],data[i]))\n",
    "        f1.append(f1_score(data[-1],data[i],average='micro'))\n",
    "    new_key_values={algorithm:{'accuracy_score':accuracyscore,'f1':f1}}\n",
    "     \n",
    "    total.update(new_key_values)\n",
    "    return total\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "146dd586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.07,random_state=85)\n",
    "Y_train=np.ravel(Y_train)\n",
    "Y_test=np.ravel(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ca59379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.51338862, -0.55622489, -0.55626612, ...,  0.29769827,\n",
       "         0.28741765,  0.27032583],\n",
       "       [-0.1119038 , -0.38043922, -0.37565821, ...,  0.94455321,\n",
       "         0.95038399,  0.95322979],\n",
       "       [-0.59935883, -0.57484363, -0.57369108, ..., -0.10787346,\n",
       "        -0.11660661, -0.14429316],\n",
       "       ...,\n",
       "       [ 1.30963316,  2.41659786,  2.41525272, ..., -0.88594264,\n",
       "        -0.8063155 , -0.66828975],\n",
       "       [ 2.27893835,  1.05074149,  1.05048886, ...,  0.90389096,\n",
       "         0.90481286,  0.89831754],\n",
       "       [-0.4466371 , -0.04000575, -0.03639299, ..., -2.09820594,\n",
       "        -2.12744809, -2.17240843]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.fit_transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc91975e",
   "metadata": {},
   "source": [
    "# linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab73212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arianzarifian/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf=LinearSVC()\n",
    "Y_predict1=clf.fit(X_train,Y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "995e14ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arianzarifian/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/arianzarifian/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf1=LinearSVC(C=5)\n",
    "clf2=LinearSVC(C=10)\n",
    "Y_predict2=clf1.fit(X_train,Y_train).predict(X_test)\n",
    "Y_predict3=clf2.fit(X_train,Y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d0f3f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear': {'accuracy_score': [0.8888888888888888,\n",
       "   0.8888888888888888,\n",
       "   0.1111111111111111],\n",
       "  'f1': [0.8888888888888888, 0.8888888888888888, 0.1111111111111111]}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy([Y_predict1,Y_predict2,Y_predict3,Y_test],'linear')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7589c540",
   "metadata": {},
   "source": [
    "# polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d22ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf1=SVC(kernel='poly',degree=10,coef0=1)\n",
    "clf1.fit(X_train,Y_train)\n",
    "Y_pred1=clf1.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67224fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2=SVC(kernel='poly',degree=3,coef0=0.5)\n",
    "clf2.fit(X_train,Y_train)\n",
    "Y_pred2=clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3ec3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3=SVC(kernel='poly',degree=7,coef0=0.5)\n",
    "clf3.fit(X_train,Y_train)\n",
    "Y_pred3=clf3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "42710851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear': {'accuracy_score': [0.8888888888888888,\n",
       "   0.8888888888888888,\n",
       "   0.1111111111111111],\n",
       "  'f1': [0.8888888888888888, 0.8888888888888888, 0.1111111111111111]},\n",
       " 'poly': {'accuracy_score': [0.8888888888888888,\n",
       "   0.8888888888888888,\n",
       "   0.8888888888888888],\n",
       "  'f1': [0.8888888888888888, 0.8888888888888888, 0.8888888888888888]}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy([Y_pred1,Y_pred2,Y_pred3,Y_test],'poly')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9da94e88",
   "metadata": {},
   "source": [
    "# RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b29ce9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=SVC()\n",
    "clf1.fit(X_train,Y_train)\n",
    "Y_pred1=clf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61a40d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2=SVC(gamma='auto')\n",
    "clf2.fit(X_train,Y_train)\n",
    "Y_pred2=clf2.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d172660",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3=SVC(gamma=4)\n",
    "clf3.fit(X_train,Y_train)\n",
    "Y_pred3=clf3.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f49f3872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear': {'accuracy_score': [0.8888888888888888,\n",
       "   0.8888888888888888,\n",
       "   0.1111111111111111],\n",
       "  'f1': [0.8888888888888888, 0.8888888888888888, 0.1111111111111111]},\n",
       " 'poly': {'accuracy_score': [0.8888888888888888,\n",
       "   0.8888888888888888,\n",
       "   0.8888888888888888],\n",
       "  'f1': [0.8888888888888888, 0.8888888888888888, 0.8888888888888888]},\n",
       " 'rbf': {'accuracy_score': [0.8888888888888888,\n",
       "   0.8888888888888888,\n",
       "   0.8888888888888888],\n",
       "  'f1': [0.8888888888888888, 0.8888888888888888, 0.8888888888888888]}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy([Y_pred1,Y_pred2,Y_pred3,Y_test],'rbf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0433b5c",
   "metadata": {},
   "source": [
    "# sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "776bffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=SVC(kernel='sigmoid',coef0=0.01)\n",
    "clf1.fit(X_train,Y_train)\n",
    "Y_pred1=clf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ceb61a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2=SVC(kernel='sigmoid',coef0=2)\n",
    "clf2.fit(X_train,Y_train)\n",
    "Y_pred2=clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d3681019",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3=SVC(kernel='sigmoid',coef0=7)\n",
    "clf3.fit(X_train,Y_train)\n",
    "Y_pred3=clf3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9b5d5397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear': {'accuracy_score': [0.8888888888888888,\n",
       "   0.8888888888888888,\n",
       "   0.1111111111111111],\n",
       "  'f1': [0.8888888888888888, 0.8888888888888888, 0.1111111111111111]},\n",
       " 'poly': {'accuracy_score': [0.8888888888888888,\n",
       "   0.8888888888888888,\n",
       "   0.8888888888888888],\n",
       "  'f1': [0.8888888888888888, 0.8888888888888888, 0.8888888888888888]},\n",
       " 'rbf': {'accuracy_score': [0.8888888888888888,\n",
       "   0.8888888888888888,\n",
       "   0.8888888888888888],\n",
       "  'f1': [0.8888888888888888, 0.8888888888888888, 0.8888888888888888]},\n",
       " 'sigmoid': {'accuracy_score': [0.6666666666666666,\n",
       "   0.8888888888888888,\n",
       "   0.8888888888888888],\n",
       "  'f1': [0.6666666666666666, 0.8888888888888888, 0.8888888888888888]}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy([Y_pred1,Y_pred2,Y_pred3,Y_test],'sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a7d0b1-9500-4a57-9fd1-5230eb3f9184",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t ب- معیار دقت و f1 را برای هریک از دسته بندی های قسمت الف به دست آورید. (برای هر یک از پارامترهای گفته شده حداقل سه مقدار مختلف در نظر بگیرید)\n",
    "\t\t</br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a6660b-18d8-40ac-b651-f1df747b871f",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t ج- تاثیر پارامترهای هر کرنل را بر کارآیی مدل ها تحلیل کنید.\n",
    "\t\t</br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7201b1-1800-4e9d-ae00-7cb5c9d673c8",
   "metadata": {},
   "source": [
    "<div id=\"bayes\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=6>\n",
    "\t\t د- کدام مدل عملکرد بهتری دارد؟ چرا؟\n",
    "\t\t</br>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0193086",
   "metadata": {},
   "source": [
    "ممکن است به دلیل کوچگ بودن دیتاست تاثیر محسوسی در تغییر پارامترها مشاهده نشد."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028f455-56e3-489b-94c3-1f77e9460a4d",
   "metadata": {},
   "source": [
    "# 3- Student Intervention System\n",
    "\n",
    "<div style=\"margin-left: 10px;font-size:25px\">a) Run the code cell below to load necessary Python libraries and load the student data. Note that the last column from this dataset, 'passed', will be our target label (whether the student graduated or didn't graduate). All other columns are features about each student.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58ad022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b3d38d1-e78a-4017-adca-b296225645b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  internet romantic  famrel  freetime  goout Dalc Walc health absences passed  \n",
       "0       no       no       4         3      4    1    1      3        6     no  \n",
       "1      yes       no       5         3      3    1    1      3        4     no  \n",
       "2      yes       no       4         3      2    2    3      3       10    yes  \n",
       "3      yes      yes       3         2      2    1    1      5        2    yes  \n",
       "4       no       no       4         3      2    1    2      5        4    yes  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data = pd.read_csv(\"student_data.csv\")\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd5509-8974-44c8-87c9-06e5aefb475c",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 10px;font-size:25px\">\n",
    "  <p>  \n",
    "b) Let's begin by investigating the dataset to determine how many students we have information on, and learn about the graduation rate among these students. In the code cell below, you will need to compute the following:\n",
    "    </p>\n",
    "    <ul>\n",
    "        <li>The total number of students, n_students.</li>\n",
    "        <li>The total number of features for each student, n_features.</li>\n",
    "        <li>The number of those students who passed, n_passed.</li>\n",
    "        <li>The number of those students who failed, n_failed.</li>\n",
    "        <li>The graduation rate of the class, grad_rate, in percent (%).</li>\n",
    "     </ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c14c9e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data.loc[student_data['passed']=='yes'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75834b0c-fd2a-45ae-bb4b-041b53ea039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of features: 30\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate number of students\n",
    "n_students = student_data.shape[0]\n",
    "\n",
    "# TODO: Calculate number of features\n",
    "n_features = student_data.shape[1]-1\n",
    "\n",
    "# TODO: Calculate passing students\n",
    "n_passed = student_data.loc[student_data['passed']=='yes'].shape[0]\n",
    "\n",
    "# TODO: Calculate failing students\n",
    "n_failed = student_data.loc[student_data['passed']=='no'].shape[0]\n",
    "\n",
    "# TODO: Calculate graduation rate\n",
    "grad_rate = (n_passed/(n_passed+n_failed))*100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of students: {}\".format(n_students))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of students who passed: {}\".format(n_passed))\n",
    "print(\"Number of students who failed: {}\".format(n_failed))\n",
    "print(\"Graduation rate of the class: {:.2f}%\".format(grad_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb98764-1eab-402f-a9c6-846417c02d75",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"margin-left: 10px;font-size:25px\">\n",
    "    <p>c) Preparing the Data</p>\n",
    "    <p>In this section, we will prepare the data for modeling, training and testing.</p>\n",
    "    <p>Identify feature and target columns\n",
    "It is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "Run the code cell below to separate the student data into feature and target columns to see if any features are non-numeric.</p>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62d65bfa-7b48-406d-b496-cb27a4db5139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Target column: passed\n"
     ]
    }
   ],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# Extract target column 'passed'\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# Show the list of columns\n",
    "print(\"Feature columns:\\n{}\".format(feature_cols))\n",
    "print(\"\\nTarget column: {}\".format(target_col))\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X = student_data[feature_cols]\n",
    "y = student_data[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a82fa-9a11-4ad5-8ed1-e61086fa3874",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 10px;font-size:25px\">\n",
    "    <p>d) Preprocess Feature Columns</p>\n",
    "    <p>As you can see, there are several non-numeric columns that need to be converted! Many of them are simply yes/no, e.g. internet. These can be reasonably converted into 1/0 (binary) values.</p>\n",
    "    <p>\n",
    "Other columns, like Mjob and Fjob, have more than two values, and are known as categorical variables. The recommended way to handle such a column is to create as many columns as possible values (e.g. Fjob_teacher, Fjob_other, Fjob_services, etc.), and assign a 1 to one of them and 0 to all others.\n",
    "\n",
    "These generated columns are sometimes called dummy variables, and we will use the pandas.get_dummies() function to perform this transformation. Run the code cell below to perform the preprocessing routine discussed in this section.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37fa60c9-b048-443a-8833-3717c637f93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****binary*****\n",
      "col name:  school----unique values:  ['GP' 'MS']\n",
      "*****binary*****\n",
      "col name:  sex----unique values:  ['F' 'M']\n",
      "*****binary*****\n",
      "col name:  address----unique values:  ['U' 'R']\n",
      "*****binary*****\n",
      "col name:  famsize----unique values:  ['GT3' 'LE3']\n",
      "*****binary*****\n",
      "col name:  Pstatus----unique values:  ['A' 'T']\n",
      "*****categorical*****\n",
      "col name:  Mjob----unique values:  ['at_home' 'health' 'other' 'services' 'teacher']\n",
      "*****categorical*****\n",
      "col name:  Fjob----unique values:  ['teacher' 'other' 'services' 'health' 'at_home']\n",
      "*****categorical*****\n",
      "col name:  reason----unique values:  ['course' 'other' 'home' 'reputation']\n",
      "*****categorical*****\n",
      "col name:  guardian----unique values:  ['mother' 'father' 'other']\n",
      "*****binary*****\n",
      "col name:  schoolsup----unique values:  ['yes' 'no']\n",
      "*****binary*****\n",
      "col name:  famsup----unique values:  ['no' 'yes']\n",
      "*****binary*****\n",
      "col name:  paid----unique values:  ['no' 'yes']\n",
      "*****binary*****\n",
      "col name:  activities----unique values:  ['no' 'yes']\n",
      "*****binary*****\n",
      "col name:  nursery----unique values:  ['yes' 'no']\n",
      "*****binary*****\n",
      "col name:  higher----unique values:  ['yes' 'no']\n",
      "*****binary*****\n",
      "col name:  internet----unique values:  ['no' 'yes']\n",
      "*****binary*****\n",
      "col name:  romantic----unique values:  ['no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the student data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.items():\n",
    "\n",
    "        # If data type is non-numeric, replace all binary values with 1/0\n",
    "        if col_data.dtype == object and len(col_data.unique()) == 2:\n",
    "            print(\"*****binary*****\")\n",
    "            print(\"col name: \", col, end=\"----\")\n",
    "            col_data_unique = col_data.unique()\n",
    "            print(\"unique values: \", col_data_unique)\n",
    "            col_data = col_data.replace(col_data_unique, [1, 0])\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object and len(col_data.unique()) != 2:\n",
    "            print(\"*****categorical*****\")\n",
    "            print(\"col name: \", col, end=\"----\")\n",
    "            col_data_unique = col_data.unique()\n",
    "            print(\"unique values: \", col_data_unique)\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_preprocessed = preprocess_features(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730323a6-decd-4da0-9f56-d15cb7126fe1",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 10px;font-size:25px\">\n",
    "    <p>e) Training and Testing Data Split</p>\n",
    "    <p>split the data (both features and corresponding labels) into training and test sets.(Use 300 training points (approximately 75%) and 95 testing points (approximately 25%).)</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d854097-e759-4d75-aa94-d02bdd5a017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import any additional functionality you may need here\n",
    "from sklearn.model_selection import train_test_split\n",
    "# TODO: split the dataset into the number of training and testing\n",
    "\n",
    "X_train, X_test, y_train ,y_test = train_test_split(X_preprocessed,y,test_size=0.25,random_state=85,stratify=student_data['studytime'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba84511-5161-437b-9ae1-625aaaed87e6",
   "metadata": {},
   "source": [
    "<div style=\"margin-left: 10px;font-size:25px\">\n",
    "<p>f) In this section, you will choose 3 supervised learning models that are appropriate for this problem and available in scikit-learn. You will first discuss the reasoning behind choosing these three models by considering what you know about the data and each model's strengths and weaknesses. You will then fit the model to training data and measure the F1 score. You will need to produce three tables (one for each model) that shows the training set size, training time, prediction time, F1 score on the training set, and F1 score on the testing set.</p>\n",
    "<p>The following supervised learning models are currently available in scikit-learn that you may choose from:</p>\n",
    "    <ul>\n",
    "        <li>Gaussian Naive Bayes (GaussianNB)</li>\n",
    "        <li>K-Nearest Neighbors (KNeighbors)</li>\n",
    "        <li>Stochastic Gradient Descent (SGDC)</li>\n",
    "        <li>Support Vector Machines (SVM)</li>\n",
    "        <li>Logistic Regression</li>\n",
    "     </ul>\n",
    "</div>    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06479bdf",
   "metadata": {},
   "source": [
    "it seems that Naive bayes can not be a suitable choice because features are not independent\n",
    "SVM should be the best one because dataset is not large\n",
    "the results of SGDC and logistic regression are assumed to be the same but SGDC should be faster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bae491b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38955227,  0.9345682 ,  0.19109751, ...,  0.5548349 ,\n",
       "        -0.37448855, -0.00441553],\n",
       "       [ 0.38955227, -1.07001287,  0.96595866, ...,  2.11152808,\n",
       "        -0.37448855,  0.94612782],\n",
       "       [ 0.38955227, -1.07001287, -1.35862478, ...,  1.33318149,\n",
       "        -1.82349   , -0.24205137],\n",
       "       ...,\n",
       "       [ 0.38955227, -1.07001287, -0.58376363, ...,  2.11152808,\n",
       "         1.0745129 ,  1.4213995 ],\n",
       "       [ 0.38955227,  0.9345682 , -0.58376363, ..., -0.22351169,\n",
       "         0.35001217, -0.12323345],\n",
       "       [ 0.38955227,  0.9345682 ,  0.19109751, ..., -1.00185828,\n",
       "        -0.37448855, -0.00441553]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X_test)\n",
    "scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04ec62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc7f3a4b",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "735f4667-513c-4315-8906-9838753cfed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "start_fit=time.time()\n",
    "gnb.fit(X_train, y_train)\n",
    "stop_fit=time.time()\n",
    "fit_time=stop_fit-start_fit\n",
    "start_pred=time.time()\n",
    "y_pred=gnb.predict(X_test)\n",
    "stop_pred=time.time()\n",
    "pred_time=stop_pred-start_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e6c08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "score_pred=f1_score(y_test,y_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c479614",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=gnb.predict(X_train)\n",
    "score_train=f1_score(y_train,y_pred_train,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a5521c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Naive=np.array([fit_time,pred_time,score_pred,score_train])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89d3d3c2",
   "metadata": {},
   "source": [
    "# K-nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2c6aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=9)\n",
    "start_fit=time.time()\n",
    "neigh.fit(X_train, y_train)\n",
    "stop_fit=time.time()\n",
    "start_pred=time.time()\n",
    "y_pred=neigh.predict(X_test)\n",
    "stop_pred=time.time()\n",
    "fit_time=stop_fit-start_fit\n",
    "pred_time=stop_pred-start_fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffd4d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred=f1_score(y_test,y_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "368c4066",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=neigh.predict(X_train)\n",
    "score_train=f1_score(y_train,y_pred_train,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16cfb51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_NN=np.array([fit_time,pred_time,score_pred,score_train])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99638026",
   "metadata": {},
   "source": [
    "# SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bebd1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf=SGDClassifier()\n",
    "\n",
    "start_fit=time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "stop_fit=time.time()\n",
    "start_pred=time.time()\n",
    "y_pred=clf.predict(X_test)\n",
    "stop_pred=time.time()\n",
    "fit_time=stop_fit-start_fit\n",
    "pred_time=stop_pred-start_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "715a9ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred=f1_score(y_test,y_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53505816",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=clf.predict(X_train)\n",
    "score_train=f1_score(y_train,y_pred_train,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b765a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGDC=np.array([fit_time,pred_time,score_pred,score_train])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3378890a",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3ea3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "cfls=SVC(C=3.0)\n",
    "start_fit=time.time()\n",
    "cfls.fit(X_train, y_train)\n",
    "stop_fit=time.time()\n",
    "start_pred=time.time()\n",
    "y_pred=cfls.predict(X_test)\n",
    "stop_pred=time.time()\n",
    "fit_time=stop_fit-start_fit\n",
    "pred_time=stop_pred-start_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de468608",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred=f1_score(y_test,y_pred,average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcaf1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=cfls.predict(X_train)\n",
    "score_train=f1_score(y_train,y_pred_train,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c79a2f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM=np.array([fit_time,pred_time,score_pred,score_train])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae163803",
   "metadata": {},
   "source": [
    "# logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "998c345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clfr=LogisticRegression(solver='liblinear',C=1.1)\n",
    "start_fit=time.time()\n",
    "clfr.fit(X_train, y_train)\n",
    "stop_fit=time.time()\n",
    "start_pred=time.time()\n",
    "y_pred=clfr.predict(X_test)\n",
    "stop_pred=time.time()\n",
    "fit_time=stop_fit-start_fit\n",
    "pred_time=stop_pred-start_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad9c7003",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred=f1_score(y_test,y_pred,average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca6e5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=neigh.predict(X_train)\n",
    "score_train=f1_score(y_train,y_pred_train,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab941a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGR=np.array([fit_time,pred_time,score_pred,score_train])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b781ec5a",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d97dd6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=arr = np.stack((Naive, K_NN,SGDC,SVM,LGR), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45e8afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=df,columns=['fit_time','pred_time','score_pred','score_train'],index=['Naive','K_NN','SGDC','SVM','LGR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b20fa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time</th>\n",
       "      <th>score_pred</th>\n",
       "      <th>score_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive</th>\n",
       "      <td>0.004409</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.733108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K_NN</th>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDC</th>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.334459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.054952</td>\n",
       "      <td>0.072472</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.722973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGR</th>\n",
       "      <td>0.008717</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fit_time  pred_time  score_pred  score_train\n",
       "Naive  0.004409   0.005868    0.676768     0.733108\n",
       "K_NN   0.002491   0.010172    0.707071     0.756757\n",
       "SGDC   0.006424   0.008284    0.333333     0.334459\n",
       "SVM    0.054952   0.072472    0.727273     0.722973\n",
       "LGR    0.008717   0.011488    0.787879     0.756757"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e61d6db4",
   "metadata": {},
   "source": [
    "انتظار می رفت که SVMبهترین نتیجه را بدهد که نشد"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1a4372f",
   "metadata": {},
   "source": [
    "اما بقیه مطابق با انتظار بوده است"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "381afda6634acabfe02de722b0985adea3cc2e228af5cdbefa626e4cfe1e2f2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
