{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5854852-35c8-4a77-a503-eb800d78ffc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hazm as hz\n",
    "from hazm import Normalizer, word_tokenize,stopwords_list,Stemmer\n",
    "import re\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import itertools    \n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout,Masking\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac6f5b9-2e27-48a5-94d1-247041996d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح</td>\n",
       "      <td>SAD</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...</td>\n",
       "      <td>SAD</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>عالللی بود همه چه درست و به اندازه و کیفیت خوب...</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>شیرینی وانیلی فقط یک مدل بود.</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                            comment  label  \\\n",
       "0        NaN    واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح    SAD   \n",
       "1        NaN  قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...  HAPPY   \n",
       "2        NaN  قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...    SAD   \n",
       "3        NaN  عالللی بود همه چه درست و به اندازه و کیفیت خوب...  HAPPY   \n",
       "4        NaN                      شیرینی وانیلی فقط یک مدل بود.  HAPPY   \n",
       "\n",
       "   label_id  \n",
       "0       1.0  \n",
       "1       0.0  \n",
       "2       1.0  \n",
       "3       0.0  \n",
       "4       0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('snappfood.csv', on_bad_lines='skip' , delimiter='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8bc0c75-f48a-43b8-b329-66fd23aa0dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69480 entries, 0 to 69999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   comment   69480 non-null  object \n",
      " 1   label_id  69480 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#remove nan values\n",
    "df=df[['comment','label_id']]\n",
    "df=df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2a03060-8946-4f17-93ad-d87fc2b01f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r\"[\\{\\}\\؛\\*\\=\\-\\_\\+\\/\\n]\",\" \",str(text))\n",
    "    text = re.sub(\"[ ]+\",\" \",text)\n",
    "    text = re.sub(\"\\!+\",\"!\",text)\n",
    "    text = re.sub(\"[؟]+\",\"؟\",text)\n",
    "    text = re.sub(\"[.]+\",\"\",text)\n",
    "    text = re.sub(\"[،]+\",\"\",text)\n",
    "    # replace Finglish words with an empty string\n",
    "    finglish_pattern = r\"[a-zA-Z]+\"\n",
    "    if finglish_pattern in text:   \n",
    "        text = re.sub(finglish_pattern, \"\", text)\n",
    "    for c in \"..آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهیئ\":\n",
    "        text = re.sub(f\"[{c}]+\", c, text)\n",
    "    # \\u200c:separate two characters that should not be connected,\\r\\n:remove line break\n",
    "    text=text.replace('\\u200c', '').replace('\\r\\n',' ').replace('|',' ')\n",
    "    #normalize the text\n",
    "    text = normalizer.normalize(text)\n",
    "    words = []\n",
    "    words.append(hz.word_tokenize(text))\n",
    "    return words\n",
    "\n",
    "train_data = df['comment'].apply(preprocess)\n",
    "df['comment'] = list(itertools.chain(*train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54cf0867-fcc6-4d0f-9a01-bf3e888c5ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "stopwords=stopwords_list()\n",
    "df['comment'] = df['comment'].apply(lambda x: ' '.join([word for word in x if word not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5c5cb56-43e9-4d0d-bc17-4a868f9699f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remove english comments\n",
    "english_text=df[df.comment.str.contains(r'[a-zA-Z]+')]\n",
    "idx=english_text.index\n",
    "df=df.drop(idx).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bf80534-8a38-4a18-b8f6-8ad28a3bd12d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find the stemm of words\n",
    "stemmer = hz.Stemmer()\n",
    "def stem_comment(comment):\n",
    "    return ' '.join([stemmer.stem(word) for word in comment.split()])\n",
    "\n",
    "# Apply stemming to 'comment' column\n",
    "df['comment'] = df['comment'].apply(stem_comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00d2cacf-ed47-4ae0-93ce-1d59880648cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=df[['comment','label_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f0e2a0e-5188-4ff6-a753-7a940675dd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>واقعا حیف وق بنویس سرویس دهیتون افتضاح</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>قرار ۱ ساعته برسه ن ساع زود موقع چقدر پلاک خفن...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قیم مدل اصلا کیفیت سازگار نداره ظاهر فریبنده د...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>درس اندازه کیف امیداور کیفیتون باشه مشتر همیشگ بش</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>شیرین وانیل مدل</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  label_id\n",
       "0             واقعا حیف وق بنویس سرویس دهیتون افتضاح       1.0\n",
       "1  قرار ۱ ساعته برسه ن ساع زود موقع چقدر پلاک خفن...       0.0\n",
       "2  قیم مدل اصلا کیفیت سازگار نداره ظاهر فریبنده د...       1.0\n",
       "3  درس اندازه کیف امیداور کیفیتون باشه مشتر همیشگ بش       0.0\n",
       "4                                    شیرین وانیل مدل       0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0678a58e-6e1b-46e9-b133-de82d72b0dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'غذا': 1, 'کیف': 2, 'سفار': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 212,  88,  63],\n",
       "       [  0,   0,   0, ...,  41, 202,  42],\n",
       "       [  0,   0,   0, ..., 100,  10,   8],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 837,   4, 246],\n",
       "       [  0,   0,   0, ..., 100,   6,  28],\n",
       "       [  0,   0,   0, ...,  54, 334,   4]], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(df['comment'])\n",
    "print(dict(list(tokenizer.word_index.items())[0:3]))\n",
    "#transforms each text in texts to a sequence of integers\n",
    "X = tokenizer.texts_to_sequences(df['comment'])\n",
    "#adding padding to comments\n",
    "X = pad_sequences(X, maxlen=100)\n",
    "# Splitting data into training and testing set\n",
    "y = df['label_id']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ce8e66f-884a-4ba2-8cab-982d386a7c05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1728/1728 [==============================] - 354s 202ms/step - loss: 0.4314 - accuracy: 0.8019 - val_loss: 0.4037 - val_accuracy: 0.8157\n",
      "Epoch 2/5\n",
      "1728/1728 [==============================] - 334s 193ms/step - loss: 0.3882 - accuracy: 0.8253 - val_loss: 0.3953 - val_accuracy: 0.8194\n",
      "Epoch 3/5\n",
      "1728/1728 [==============================] - 344s 199ms/step - loss: 0.3749 - accuracy: 0.8319 - val_loss: 0.3941 - val_accuracy: 0.8210\n",
      "Epoch 4/5\n",
      "1728/1728 [==============================] - 370s 214ms/step - loss: 0.3645 - accuracy: 0.8365 - val_loss: 0.3973 - val_accuracy: 0.8239\n",
      "Epoch 5/5\n",
      "1728/1728 [==============================] - 360s 208ms/step - loss: 0.3571 - accuracy: 0.8399 - val_loss: 0.3948 - val_accuracy: 0.8239\n",
      "Accuracy: 82.39%\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0))\n",
    "    model.add(Embedding(10000, 128, input_length=100))\n",
    "    model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "model=get_model()\n",
    "# Training model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (score[1]*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
